{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc82983-0013-4314-a15b-48e959a67df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenet_1.00_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,228,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenet_1.00_128 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m3,228,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m1,179,776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,671,553</span> (17.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,671,553\u001b[0m (17.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,442,433</span> (5.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,442,433\u001b[0m (5.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,229,120</span> (12.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,229,120\u001b[0m (12.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.60152835 0.60152835 0.60152835]\n",
      "   [0.6200873  0.6200873  0.6200873 ]\n",
      "   [0.6408297  0.6408297  0.6408297 ]\n",
      "   ...\n",
      "   [0.6342795  0.6342795  0.6342795 ]\n",
      "   [0.59388644 0.59388644 0.59388644]\n",
      "   [0.58515286 0.58515286 0.58515286]]\n",
      "\n",
      "  [[0.5753275  0.5753275  0.5753275 ]\n",
      "   [0.58078605 0.58078605 0.58078605]\n",
      "   [0.57641923 0.57641923 0.57641923]\n",
      "   ...\n",
      "   [0.5786027  0.5786027  0.5786027 ]\n",
      "   [0.58078605 0.58078605 0.58078605]\n",
      "   [0.5742358  0.5742358  0.5742358 ]]\n",
      "\n",
      "  [[0.5753275  0.5753275  0.5753275 ]\n",
      "   [0.5753275  0.5753275  0.5753275 ]\n",
      "   [0.59061134 0.59061134 0.59061134]\n",
      "   ...\n",
      "   [0.5731441  0.5731441  0.5731441 ]\n",
      "   [0.5687773  0.5687773  0.5687773 ]\n",
      "   [0.55021834 0.55021834 0.55021834]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5753275  0.5753275  0.5753275 ]\n",
      "   [0.5927948  0.5927948  0.5927948 ]\n",
      "   [0.6069869  0.6069869  0.6069869 ]\n",
      "   ...\n",
      "   [0.58406115 0.58406115 0.58406115]\n",
      "   [0.59497815 0.59497815 0.59497815]\n",
      "   [0.5862445  0.5862445  0.5862445 ]]\n",
      "\n",
      "  [[0.5676856  0.5676856  0.5676856 ]\n",
      "   [0.5873363  0.5873363  0.5873363 ]\n",
      "   [0.59497815 0.59497815 0.59497815]\n",
      "   ...\n",
      "   [0.58842796 0.58842796 0.58842796]\n",
      "   [0.57314414 0.57314414 0.57314414]\n",
      "   [0.5742358  0.5742358  0.5742358 ]]\n",
      "\n",
      "  [[0.5796944  0.5796944  0.5796944 ]\n",
      "   [0.5873363  0.5873363  0.5873363 ]\n",
      "   [0.57641923 0.57641923 0.57641923]\n",
      "   ...\n",
      "   [0.588428   0.588428   0.588428  ]\n",
      "   [0.5676856  0.5676856  0.5676856 ]\n",
      "   [0.5262009  0.5262009  0.5262009 ]]]\n",
      "\n",
      "\n",
      " [[[0.6816144  0.6816144  0.6816144 ]\n",
      "   [0.64910316 0.64910316 0.64910316]\n",
      "   [0.6300448  0.6300448  0.6300448 ]\n",
      "   ...\n",
      "   [0.67152464 0.67152464 0.67152464]\n",
      "   [0.7017937  0.7017937  0.7017937 ]\n",
      "   [0.690583   0.690583   0.690583  ]]\n",
      "\n",
      "  [[0.58408076 0.58408076 0.58408076]\n",
      "   [0.64798206 0.64798206 0.64798206]\n",
      "   [0.6311659  0.6311659  0.6311659 ]\n",
      "   ...\n",
      "   [0.6143497  0.6143497  0.6143497 ]\n",
      "   [0.62331843 0.62331843 0.62331843]\n",
      "   [0.60201794 0.60201794 0.60201794]]\n",
      "\n",
      "  [[0.65134525 0.65134525 0.65134525]\n",
      "   [0.6278027  0.6278027  0.6278027 ]\n",
      "   [0.6210762  0.6210762  0.6210762 ]\n",
      "   ...\n",
      "   [0.5863229  0.5863229  0.5863229 ]\n",
      "   [0.66816145 0.66816145 0.66816145]\n",
      "   [0.62219733 0.62219733 0.62219733]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6266816  0.6266816  0.6266816 ]\n",
      "   [0.63789237 0.63789237 0.63789237]\n",
      "   [0.6087444  0.6087444  0.6087444 ]\n",
      "   ...\n",
      "   [0.6244395  0.6244395  0.6244395 ]\n",
      "   [0.6345291  0.6345291  0.6345291 ]\n",
      "   [0.617713   0.617713   0.617713  ]]\n",
      "\n",
      "  [[0.64910316 0.64910316 0.64910316]\n",
      "   [0.6558296  0.6558296  0.6558296 ]\n",
      "   [0.64461887 0.64461887 0.64461887]\n",
      "   ...\n",
      "   [0.6412556  0.6412556  0.6412556 ]\n",
      "   [0.6401345  0.6401345  0.6401345 ]\n",
      "   [0.6356502  0.6356502  0.6356502 ]]\n",
      "\n",
      "  [[0.6356502  0.6356502  0.6356502 ]\n",
      "   [0.6244395  0.6244395  0.6244395 ]\n",
      "   [0.5941704  0.5941704  0.5941704 ]\n",
      "   ...\n",
      "   [0.6188341  0.6188341  0.6188341 ]\n",
      "   [0.6221973  0.6221973  0.6221973 ]\n",
      "   [0.6356503  0.6356503  0.6356503 ]]]\n",
      "\n",
      "\n",
      " [[[0.5721983  0.5721983  0.5721983 ]\n",
      "   [0.5721983  0.5721983  0.5721983 ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.56896555 0.56896555 0.56896555]\n",
      "   [0.55818963 0.55818963 0.55818963]\n",
      "   [0.5786638  0.5786638  0.5786638 ]]\n",
      "\n",
      "  [[0.5646552  0.5646552  0.5646552 ]\n",
      "   [0.5646552  0.5646552  0.5646552 ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.57543105 0.57543105 0.57543105]\n",
      "   [0.57327586 0.57327586 0.57327586]\n",
      "   [0.5635776  0.5635776  0.5635776 ]]\n",
      "\n",
      "  [[0.55064654 0.55064654 0.55064654]\n",
      "   [0.56896555 0.56896555 0.56896555]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.56896555 0.56896555 0.56896555]\n",
      "   [0.56896555 0.56896555 0.56896555]\n",
      "   [0.5625     0.5625     0.5625    ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5711207  0.5711207  0.5711207 ]\n",
      "   [0.56681037 0.56681037 0.56681037]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.57327586 0.57327586 0.57327586]\n",
      "   [0.57435346 0.57435346 0.57435346]\n",
      "   [0.5614224  0.5614224  0.5614224 ]]\n",
      "\n",
      "  [[0.5657328  0.5657328  0.5657328 ]\n",
      "   [0.5549569  0.5549569  0.5549569 ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.5657327  0.5657327  0.5657327 ]\n",
      "   [0.5614224  0.5614224  0.5614224 ]\n",
      "   [0.5549569  0.5549569  0.5549569 ]]\n",
      "\n",
      "  [[0.55064654 0.55064654 0.55064654]\n",
      "   [0.54418105 0.54418105 0.54418105]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.57758623 0.57758623 0.57758623]\n",
      "   [0.5689655  0.5689655  0.5689655 ]\n",
      "   [0.54849136 0.54849136 0.54849136]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.7380952  0.7380952  0.7380952 ]\n",
      "   [0.7348485  0.7348485  0.7348485 ]\n",
      "   [0.7532468  0.7532468  0.7532468 ]\n",
      "   ...\n",
      "   [0.719697   0.719697   0.719697  ]\n",
      "   [0.741342   0.741342   0.741342  ]\n",
      "   [0.7099567  0.7099567  0.7099567 ]]\n",
      "\n",
      "  [[0.74891776 0.74891776 0.74891776]\n",
      "   [0.74891776 0.74891776 0.74891776]\n",
      "   [0.737013   0.737013   0.737013  ]\n",
      "   ...\n",
      "   [0.77272725 0.77272725 0.77272725]\n",
      "   [0.7532468  0.7532468  0.7532468 ]\n",
      "   [0.73917747 0.73917747 0.73917747]]\n",
      "\n",
      "  [[0.64069265 0.64069265 0.64069265]\n",
      "   [0.719697   0.719697   0.719697  ]\n",
      "   [0.72402596 0.72402596 0.72402596]\n",
      "   ...\n",
      "   [0.74458873 0.74458873 0.74458873]\n",
      "   [0.7186147  0.7186147  0.7186147 ]\n",
      "   [0.75757575 0.75757575 0.75757575]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7532468  0.7532468  0.7532468 ]\n",
      "   [0.69264066 0.69264066 0.69264066]\n",
      "   [0.7316017  0.7316017  0.7316017 ]\n",
      "   ...\n",
      "   [0.72402596 0.72402596 0.72402596]\n",
      "   [0.7348485  0.7348485  0.7348485 ]\n",
      "   [0.74242425 0.74242425 0.74242425]]\n",
      "\n",
      "  [[0.7662338  0.7662338  0.7662338 ]\n",
      "   [0.715368   0.715368   0.715368  ]\n",
      "   [0.7316017  0.7316017  0.7316017 ]\n",
      "   ...\n",
      "   [0.767316   0.767316   0.767316  ]\n",
      "   [0.7651515  0.7651515  0.7651515 ]\n",
      "   [0.7564935  0.7564935  0.7564935 ]]\n",
      "\n",
      "  [[0.7207792  0.7207792  0.7207792 ]\n",
      "   [0.76406926 0.76406926 0.76406926]\n",
      "   [0.72402596 0.72402596 0.72402596]\n",
      "   ...\n",
      "   [0.7316017  0.7316017  0.7316017 ]\n",
      "   [0.7348485  0.7348485  0.7348485 ]\n",
      "   [0.66883117 0.66883117 0.66883117]]]\n",
      "\n",
      "\n",
      " [[[0.52678573 0.52678573 0.52678573]\n",
      "   [0.50111604 0.50111604 0.50111604]\n",
      "   [0.53571427 0.53571427 0.53571427]\n",
      "   ...\n",
      "   [0.55357146 0.55357146 0.55357146]\n",
      "   [0.51116073 0.51116073 0.51116073]\n",
      "   [0.5212053  0.5212053  0.5212053 ]]\n",
      "\n",
      "  [[0.5892857  0.5892857  0.5892857 ]\n",
      "   [0.51339287 0.51339287 0.51339287]\n",
      "   [0.54799104 0.54799104 0.54799104]\n",
      "   ...\n",
      "   [0.45535713 0.45535713 0.45535713]\n",
      "   [0.4921875  0.4921875  0.4921875 ]\n",
      "   [0.55357146 0.55357146 0.55357146]]\n",
      "\n",
      "  [[0.54464287 0.54464287 0.54464287]\n",
      "   [0.56808037 0.56808037 0.56808037]\n",
      "   [0.5524553  0.5524553  0.5524553 ]\n",
      "   ...\n",
      "   [0.5178572  0.5178572  0.5178572 ]\n",
      "   [0.52790177 0.52790177 0.52790177]\n",
      "   [0.546875   0.546875   0.546875  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.55803573 0.55803573 0.55803573]\n",
      "   [0.5290178  0.5290178  0.5290178 ]\n",
      "   [0.57924104 0.57924104 0.57924104]\n",
      "   ...\n",
      "   [0.4955357  0.4955357  0.4955357 ]\n",
      "   [0.54241073 0.54241073 0.54241073]\n",
      "   [0.49888393 0.49888393 0.49888393]]\n",
      "\n",
      "  [[0.52790177 0.52790177 0.52790177]\n",
      "   [0.55803573 0.55803573 0.55803573]\n",
      "   [0.5725447  0.5725447  0.5725447 ]\n",
      "   ...\n",
      "   [0.53236604 0.53236604 0.53236604]\n",
      "   [0.53794646 0.53794646 0.53794646]\n",
      "   [0.4754464  0.4754464  0.4754464 ]]\n",
      "\n",
      "  [[0.55357146 0.55357146 0.55357146]\n",
      "   [0.58147323 0.58147323 0.58147323]\n",
      "   [0.55245537 0.55245537 0.55245537]\n",
      "   ...\n",
      "   [0.56026787 0.56026787 0.56026787]\n",
      "   [0.51450896 0.51450896 0.51450896]\n",
      "   [0.48325893 0.48325893 0.48325893]]]\n",
      "\n",
      "\n",
      " [[[0.5681818  0.5681818  0.5681818 ]\n",
      "   [0.5595238  0.5595238  0.5595238 ]\n",
      "   [0.5649351  0.5649351  0.5649351 ]\n",
      "   ...\n",
      "   [0.5649351  0.5649351  0.5649351 ]\n",
      "   [0.56926405 0.56926405 0.56926405]\n",
      "   [0.5757576  0.5757576  0.5757576 ]]\n",
      "\n",
      "  [[0.534632   0.534632   0.534632  ]\n",
      "   [0.5551948  0.5551948  0.5551948 ]\n",
      "   [0.5476191  0.5476191  0.5476191 ]\n",
      "   ...\n",
      "   [0.55411255 0.55411255 0.55411255]\n",
      "   [0.5681818  0.5681818  0.5681818 ]\n",
      "   [0.56277055 0.56277055 0.56277055]]\n",
      "\n",
      "  [[0.5627706  0.5627706  0.5627706 ]\n",
      "   [0.55411255 0.55411255 0.55411255]\n",
      "   [0.5822511  0.5822511  0.5822511 ]\n",
      "   ...\n",
      "   [0.5616883  0.5616883  0.5616883 ]\n",
      "   [0.5649351  0.5649351  0.5649351 ]\n",
      "   [0.57034636 0.57034636 0.57034636]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5714286  0.5714286  0.5714286 ]\n",
      "   [0.5714286  0.5714286  0.5714286 ]\n",
      "   [0.56926405 0.56926405 0.56926405]\n",
      "   ...\n",
      "   [0.57142854 0.57142854 0.57142854]\n",
      "   [0.57142854 0.57142854 0.57142854]\n",
      "   [0.57142854 0.57142854 0.57142854]]\n",
      "\n",
      "  [[0.5670996  0.5670996  0.5670996 ]\n",
      "   [0.5681818  0.5681818  0.5681818 ]\n",
      "   [0.5800866  0.5800866  0.5800866 ]\n",
      "   ...\n",
      "   [0.5551948  0.5551948  0.5551948 ]\n",
      "   [0.5551948  0.5551948  0.5551948 ]\n",
      "   [0.5432901  0.5432901  0.5432901 ]]\n",
      "\n",
      "  [[0.56060606 0.56060606 0.56060606]\n",
      "   [0.57251084 0.57251084 0.57251084]\n",
      "   [0.5584415  0.5584415  0.5584415 ]\n",
      "   ...\n",
      "   [0.52056277 0.52056277 0.52056277]\n",
      "   [0.52597404 0.52597404 0.52597404]\n",
      "   [0.44155845 0.44155845 0.44155845]]]] [[[[0.69603527 0.69603527 0.69603527]\n",
      "   [0.6685022  0.6685022  0.6685022 ]\n",
      "   [0.7169604  0.7169604  0.7169604 ]\n",
      "   ...\n",
      "   [0.72246695 0.72246695 0.72246695]\n",
      "   [0.6442731  0.6442731  0.6442731 ]\n",
      "   [0.68061674 0.68061674 0.68061674]]\n",
      "\n",
      "  [[0.7268722  0.7268722  0.7268722 ]\n",
      "   [0.6762115  0.6762115  0.6762115 ]\n",
      "   [0.6762114  0.6762114  0.6762114 ]\n",
      "   ...\n",
      "   [0.6795154  0.6795154  0.6795154 ]\n",
      "   [0.67180616 0.67180616 0.67180616]\n",
      "   [0.70594716 0.70594716 0.70594716]]\n",
      "\n",
      "  [[0.69052863 0.69052863 0.69052863]\n",
      "   [0.65418506 0.65418506 0.65418506]\n",
      "   [0.71255505 0.71255505 0.71255505]\n",
      "   ...\n",
      "   [0.6982379  0.6982379  0.6982379 ]\n",
      "   [0.72687227 0.72687227 0.72687227]\n",
      "   [0.71145374 0.71145374 0.71145374]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.68061674 0.68061674 0.68061674]\n",
      "   [0.6640969  0.6640969  0.6640969 ]\n",
      "   [0.6993392  0.6993392  0.6993392 ]\n",
      "   ...\n",
      "   [0.65198237 0.65198237 0.65198237]\n",
      "   [0.6784141  0.6784141  0.6784141 ]\n",
      "   [0.6982379  0.6982379  0.6982379 ]]\n",
      "\n",
      "  [[0.6530837  0.6530837  0.6530837 ]\n",
      "   [0.65088105 0.65088105 0.65088105]\n",
      "   [0.6982379  0.6982379  0.6982379 ]\n",
      "   ...\n",
      "   [0.69162995 0.69162995 0.69162995]\n",
      "   [0.72136563 0.72136563 0.72136563]\n",
      "   [0.67731273 0.67731273 0.67731273]]\n",
      "\n",
      "  [[0.7257709  0.7257709  0.7257709 ]\n",
      "   [0.71145374 0.71145374 0.71145374]\n",
      "   [0.7246696  0.7246696  0.7246696 ]\n",
      "   ...\n",
      "   [0.6552863  0.6552863  0.6552863 ]\n",
      "   [0.74229074 0.74229074 0.74229074]\n",
      "   [0.7092511  0.7092511  0.7092511 ]]]\n",
      "\n",
      "\n",
      " [[[0.5715859  0.5715859  0.5715859 ]\n",
      "   [0.58810574 0.58810574 0.58810574]\n",
      "   [0.58810574 0.58810574 0.58810574]\n",
      "   ...\n",
      "   [0.56607926 0.56607926 0.56607926]\n",
      "   [0.58590305 0.58590305 0.58590305]\n",
      "   [0.5859031  0.5859031  0.5859031 ]]\n",
      "\n",
      "  [[0.5837004  0.5837004  0.5837004 ]\n",
      "   [0.58810574 0.58810574 0.58810574]\n",
      "   [0.58810574 0.58810574 0.58810574]\n",
      "   ...\n",
      "   [0.5803965  0.5803965  0.5803965 ]\n",
      "   [0.5837004  0.5837004  0.5837004 ]\n",
      "   [0.5848018  0.5848018  0.5848018 ]]\n",
      "\n",
      "  [[0.5715859  0.5715859  0.5715859 ]\n",
      "   [0.5870044  0.5870044  0.5870044 ]\n",
      "   [0.5814978  0.5814978  0.5814978 ]\n",
      "   ...\n",
      "   [0.5814978  0.5814978  0.5814978 ]\n",
      "   [0.5814978  0.5814978  0.5814978 ]\n",
      "   [0.5770925  0.5770925  0.5770925 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5605726  0.5605726  0.5605726 ]\n",
      "   [0.59911895 0.59911895 0.59911895]\n",
      "   [0.61563873 0.61563873 0.61563873]\n",
      "   ...\n",
      "   [0.5848018  0.5848018  0.5848018 ]\n",
      "   [0.5837004  0.5837004  0.5837004 ]\n",
      "   [0.60022026 0.60022026 0.60022026]]\n",
      "\n",
      "  [[0.5715859  0.5715859  0.5715859 ]\n",
      "   [0.57599115 0.57599115 0.57599115]\n",
      "   [0.564978   0.564978   0.564978  ]\n",
      "   ...\n",
      "   [0.5638766  0.5638766  0.5638766 ]\n",
      "   [0.5770925  0.5770925  0.5770925 ]\n",
      "   [0.5627753  0.5627753  0.5627753 ]]\n",
      "\n",
      "  [[0.56938326 0.56938326 0.56938326]\n",
      "   [0.5638766  0.5638766  0.5638766 ]\n",
      "   [0.5881057  0.5881057  0.5881057 ]\n",
      "   ...\n",
      "   [0.5770925  0.5770925  0.5770925 ]\n",
      "   [0.59030837 0.59030837 0.59030837]\n",
      "   [0.5770925  0.5770925  0.5770925 ]]]\n",
      "\n",
      "\n",
      " [[[0.6648707  0.6648707  0.6648707 ]\n",
      "   [0.6400862  0.6400862  0.6400862 ]\n",
      "   [0.7165948  0.7165948  0.7165948 ]\n",
      "   ...\n",
      "   [0.7338362  0.7338362  0.7338362 ]\n",
      "   [0.6465517  0.6465517  0.6465517 ]\n",
      "   [0.68103445 0.68103445 0.68103445]]\n",
      "\n",
      "  [[0.72952586 0.72952586 0.72952586]\n",
      "   [0.6465517  0.6465517  0.6465517 ]\n",
      "   [0.7112069  0.7112069  0.7112069 ]\n",
      "   ...\n",
      "   [0.70689654 0.70689654 0.70689654]\n",
      "   [0.6799569  0.6799569  0.6799569 ]\n",
      "   [0.66810346 0.66810346 0.66810346]]\n",
      "\n",
      "  [[0.65625    0.65625    0.65625   ]\n",
      "   [0.61099136 0.61099136 0.61099136]\n",
      "   [0.66702586 0.66702586 0.66702586]\n",
      "   ...\n",
      "   [0.68103445 0.68103445 0.68103445]\n",
      "   [0.67025864 0.67025864 0.67025864]\n",
      "   [0.6939655  0.6939655  0.6939655 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.66702586 0.66702586 0.66702586]\n",
      "   [0.67025864 0.67025864 0.67025864]\n",
      "   [0.66810346 0.66810346 0.66810346]\n",
      "   ...\n",
      "   [0.6821121  0.6821121  0.6821121 ]\n",
      "   [0.64978445 0.64978445 0.64978445]\n",
      "   [0.66487074 0.66487074 0.66487074]]\n",
      "\n",
      "  [[0.6928879  0.6928879  0.6928879 ]\n",
      "   [0.6767242  0.6767242  0.6767242 ]\n",
      "   [0.65625    0.65625    0.65625   ]\n",
      "   ...\n",
      "   [0.6530173  0.6530173  0.6530173 ]\n",
      "   [0.731681   0.731681   0.731681  ]\n",
      "   [0.68642247 0.68642247 0.68642247]]\n",
      "\n",
      "  [[0.6810345  0.6810345  0.6810345 ]\n",
      "   [0.669181   0.669181   0.669181  ]\n",
      "   [0.63685346 0.63685346 0.63685346]\n",
      "   ...\n",
      "   [0.65625    0.65625    0.65625   ]\n",
      "   [0.7284483  0.7284483  0.7284483 ]\n",
      "   [0.68318963 0.68318963 0.68318963]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.5751121  0.5751121  0.5751121 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.529148   0.529148   0.529148  ]\n",
      "   [0.5526906  0.5526906  0.5526906 ]\n",
      "   [0.58295965 0.58295965 0.58295965]]\n",
      "\n",
      "  [[0.5616592  0.5616592  0.5616592 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.5795964  0.5795964  0.5795964 ]\n",
      "   [0.5706278  0.5706278  0.5706278 ]\n",
      "   [0.5840807  0.5840807  0.5840807 ]]\n",
      "\n",
      "  [[0.5526906  0.5526906  0.5526906 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.5695067  0.5695067  0.5695067 ]\n",
      "   [0.5403587  0.5403587  0.5403587 ]\n",
      "   [0.5795964  0.5795964  0.5795964 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5908072  0.5908072  0.5908072 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.59192824 0.59192824 0.59192824]\n",
      "   [0.59192824 0.59192824 0.59192824]\n",
      "   [0.5896861  0.5896861  0.5896861 ]]\n",
      "\n",
      "  [[0.6042601  0.6042601  0.6042601 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.60089684 0.60089684 0.60089684]\n",
      "   [0.58856505 0.58856505 0.58856505]\n",
      "   [0.59865475 0.59865475 0.59865475]]\n",
      "\n",
      "  [[0.6973094  0.6973094  0.6973094 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.72197306 0.72197306 0.72197306]\n",
      "   [0.72197306 0.72197306 0.72197306]\n",
      "   [0.7051569  0.7051569  0.7051569 ]]]\n",
      "\n",
      "\n",
      " [[[0.6271367  0.6271367  0.6271367 ]\n",
      "   [0.66025645 0.66025645 0.66025645]\n",
      "   [0.6132479  0.6132479  0.6132479 ]\n",
      "   ...\n",
      "   [0.65918803 0.65918803 0.65918803]\n",
      "   [0.70619655 0.70619655 0.70619655]\n",
      "   [0.6666667  0.6666667  0.6666667 ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.68482906 0.68482906 0.68482906]\n",
      "   [0.66880345 0.66880345 0.66880345]\n",
      "   [0.68162394 0.68162394 0.68162394]\n",
      "   ...\n",
      "   [0.64850426 0.64850426 0.64850426]\n",
      "   [0.6752137  0.6752137  0.6752137 ]\n",
      "   [0.6346154  0.6346154  0.6346154 ]]\n",
      "\n",
      "  [[0.59081197 0.59081197 0.59081197]\n",
      "   [0.60470086 0.60470086 0.60470086]\n",
      "   [0.67628205 0.67628205 0.67628205]\n",
      "   ...\n",
      "   [0.6837607  0.6837607  0.6837607 ]\n",
      "   [0.67414534 0.67414534 0.67414534]\n",
      "   [0.63247865 0.63247865 0.63247865]]\n",
      "\n",
      "  [[0.69658124 0.69658124 0.69658124]\n",
      "   [0.6880342  0.6880342  0.6880342 ]\n",
      "   [0.6132479  0.6132479  0.6132479 ]\n",
      "   ...\n",
      "   [0.6559829  0.6559829  0.6559829 ]\n",
      "   [0.732906   0.732906   0.732906  ]\n",
      "   [0.7051282  0.7051282  0.7051282 ]]]\n",
      "\n",
      "\n",
      " [[[0.6949339  0.6949339  0.6949339 ]\n",
      "   [0.67731273 0.67731273 0.67731273]\n",
      "   [0.69052863 0.69052863 0.69052863]\n",
      "   ...\n",
      "   [0.67070484 0.67070484 0.67070484]\n",
      "   [0.7136564  0.7136564  0.7136564 ]\n",
      "   [0.7070485  0.7070485  0.7070485 ]]\n",
      "\n",
      "  [[0.74449337 0.74449337 0.74449337]\n",
      "   [0.7334802  0.7334802  0.7334802 ]\n",
      "   [0.7235683  0.7235683  0.7235683 ]\n",
      "   ...\n",
      "   [0.7632159  0.7632159  0.7632159 ]\n",
      "   [0.722467   0.722467   0.722467  ]\n",
      "   [0.7411895  0.7411895  0.7411895 ]]\n",
      "\n",
      "  [[0.6585903  0.6585903  0.6585903 ]\n",
      "   [0.70154184 0.70154184 0.70154184]\n",
      "   [0.6751101  0.6751101  0.6751101 ]\n",
      "   ...\n",
      "   [0.69273126 0.69273126 0.69273126]\n",
      "   [0.6762115  0.6762115  0.6762115 ]\n",
      "   [0.69162995 0.69162995 0.69162995]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.65418506 0.65418506 0.65418506]\n",
      "   [0.6993392  0.6993392  0.6993392 ]\n",
      "   [0.64096916 0.64096916 0.64096916]\n",
      "   ...\n",
      "   [0.6993393  0.6993393  0.6993393 ]\n",
      "   [0.6795154  0.6795154  0.6795154 ]\n",
      "   [0.6629956  0.6629956  0.6629956 ]]\n",
      "\n",
      "  [[0.68171805 0.68171805 0.68171805]\n",
      "   [0.6464758  0.6464758  0.6464758 ]\n",
      "   [0.65969163 0.65969163 0.65969163]\n",
      "   ...\n",
      "   [0.64427316 0.64427316 0.64427316]\n",
      "   [0.685022   0.685022   0.685022  ]\n",
      "   [0.6971365  0.6971365  0.6971365 ]]\n",
      "\n",
      "  [[0.67400885 0.67400885 0.67400885]\n",
      "   [0.65418506 0.65418506 0.65418506]\n",
      "   [0.6949339  0.6949339  0.6949339 ]\n",
      "   ...\n",
      "   [0.66079295 0.66079295 0.66079295]\n",
      "   [0.6861234  0.6861234  0.6861234 ]\n",
      "   [0.715859   0.715859   0.715859  ]]]] [0 1 1 ... 0 0 1] [1 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, BatchNormalization, ReLU\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2  # Import L2 regularizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to preprocess spectrograms\n",
    "def preprocess_spectrogram(spectrogram, target_size):\n",
    "    # Normalize\n",
    "    spectrogram = spectrogram / np.max(spectrogram)\n",
    "    # Resize to match MobileNet input\n",
    "    spectrogram = tf.image.resize(spectrogram, target_size)\n",
    "    # Convert to 3 channels (stack the same data for all channels)\n",
    "    spectrogram = tf.image.grayscale_to_rgb(spectrogram)\n",
    "    return spectrogram.numpy()\n",
    "\n",
    "# Data augmentation for spectrograms\n",
    "def augment_spectrogram(spectrogram):\n",
    "    # Time shifting\n",
    "    shift = random.randint(-10, 10)\n",
    "    spectrogram = np.roll(spectrogram, shift, axis=1)\n",
    "\n",
    "    # Frequency masking\n",
    "    freq_mask = random.randint(0, 10)\n",
    "    spectrogram[:, freq_mask:freq_mask + 10, :] = 0\n",
    "\n",
    "    # Time masking\n",
    "    time_mask = random.randint(0, 10)\n",
    "    spectrogram[time_mask:time_mask + 10, :, :] = 0\n",
    "\n",
    "    return spectrogram\n",
    "\n",
    "# Create a model with MobileNetV2 as the base and L2 regularization\n",
    "def create_model(input_shape):\n",
    "    # Load MobileNetV2 without the top layers\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Fine-tune MobileNetV2\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    #base_model.trainable = True\n",
    "    for layer in base_model.layers[-3:0]:  # Freeze the first 100 layers\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Add custom layers with L2 regularization\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),  # L2 regularization\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  # L2 regularization\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01))  # L2 regularization\n",
    "    ])\n",
    "    return model\n",
    "# Load and preprocess spectrogram dataset\n",
    "def load_data(image_folder, txt_folder, target_size):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    # Read labels and corresponding spectrogram paths\n",
    "    for txt_file in os.listdir(txt_folder):\n",
    "        if txt_file.endswith('.txt'):\n",
    "            with open(os.path.join(txt_folder, txt_file), 'r') as file:\n",
    "                label = int(file.read().strip())\n",
    "                image_name = os.path.splitext(txt_file)[0] + '.jpg'  # Assuming spectrograms are in .jpg format\n",
    "                image_path = os.path.join(image_folder, image_name)\n",
    "                if os.path.exists(image_path):\n",
    "                    image_paths.append(image_path)\n",
    "                    labels.append(label)\n",
    "\n",
    "    # Preprocess spectrograms\n",
    "    X = []\n",
    "    y = []\n",
    "    for img_path, label in zip(image_paths, labels):\n",
    "        spectrogram = tf.keras.preprocessing.image.load_img(img_path, color_mode='grayscale')\n",
    "        spectrogram = tf.keras.preprocessing.image.img_to_array(spectrogram)\n",
    "        spectrogram = preprocess_spectrogram(spectrogram, target_size)\n",
    "        spectrogram = augment_spectrogram(spectrogram)  # Apply augmentation\n",
    "        X.append(spectrogram)\n",
    "        y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Input shape for spectrograms\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "# Create the model\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# Paths to dataset\n",
    "image_folder = 'Dataset_Model/Final_dataset/56k_train_images'  # Replace with your training spectrogram images path\n",
    "txt_folder = 'Dataset_Model/Final_dataset/56k_train_labels'  # Replace with your training labels path\n",
    "\n",
    "# Load data\n",
    "X, y = load_data(image_folder, txt_folder, (128, 128))\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbe0af40-aa6e-4d1b-8b90-c899a7388afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (51200, 128, 128, 3)\n",
      "X_val shape: (12800, 128, 128, 3)\n",
      "y_train shape: (51200,)\n",
      "y_val shape: (12800,)\n",
      "Training labels distribution: [12800 38400]\n",
      "Validation labels distribution: [3200 9600]\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "\n",
    "print(f\"Training labels distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Validation labels distribution: {np.bincount(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83e399c-87c9-4466-9422-7e187009b5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.3.1/libexec/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 181ms/step - accuracy: 0.8021 - loss: 4.9442 - precision: 0.8352 - recall: 0.9193 - val_accuracy: 0.9006 - val_loss: 4.1412 - val_precision: 0.8967 - val_recall: 0.9804 - learning_rate: 1.0000e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 192ms/step - accuracy: 0.8925 - loss: 3.9739 - precision: 0.9002 - recall: 0.9641 - val_accuracy: 0.9047 - val_loss: 3.4424 - val_precision: 0.9049 - val_recall: 0.9754 - learning_rate: 1.0000e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 196ms/step - accuracy: 0.9031 - loss: 3.3076 - precision: 0.9076 - recall: 0.9694 - val_accuracy: 0.9091 - val_loss: 2.8961 - val_precision: 0.9122 - val_recall: 0.9724 - learning_rate: 1.0000e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 187ms/step - accuracy: 0.9119 - loss: 2.7854 - precision: 0.9150 - recall: 0.9734 - val_accuracy: 0.9093 - val_loss: 2.4725 - val_precision: 0.9237 - val_recall: 0.9582 - learning_rate: 1.0000e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 188ms/step - accuracy: 0.9144 - loss: 2.3779 - precision: 0.9185 - recall: 0.9723 - val_accuracy: 0.9127 - val_loss: 2.1355 - val_precision: 0.9108 - val_recall: 0.9795 - learning_rate: 1.0000e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 188ms/step - accuracy: 0.9159 - loss: 2.0601 - precision: 0.9206 - recall: 0.9721 - val_accuracy: 0.9137 - val_loss: 1.8677 - val_precision: 0.9180 - val_recall: 0.9718 - learning_rate: 1.0000e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 204ms/step - accuracy: 0.9187 - loss: 1.8069 - precision: 0.9229 - recall: 0.9733 - val_accuracy: 0.9150 - val_loss: 1.6580 - val_precision: 0.9139 - val_recall: 0.9789 - learning_rate: 1.0000e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 203ms/step - accuracy: 0.9238 - loss: 1.6007 - precision: 0.9262 - recall: 0.9766 - val_accuracy: 0.9142 - val_loss: 1.4921 - val_precision: 0.9252 - val_recall: 0.9635 - learning_rate: 1.0000e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 200ms/step - accuracy: 0.9259 - loss: 1.4387 - precision: 0.9292 - recall: 0.9752 - val_accuracy: 0.9157 - val_loss: 1.3515 - val_precision: 0.9155 - val_recall: 0.9778 - learning_rate: 1.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 214ms/step - accuracy: 0.9279 - loss: 1.3030 - precision: 0.9301 - recall: 0.9770 - val_accuracy: 0.9155 - val_loss: 1.2372 - val_precision: 0.9204 - val_recall: 0.9714 - learning_rate: 1.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 216ms/step - accuracy: 0.9278 - loss: 1.1927 - precision: 0.9313 - recall: 0.9753 - val_accuracy: 0.9157 - val_loss: 1.1410 - val_precision: 0.9238 - val_recall: 0.9674 - learning_rate: 1.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 211ms/step - accuracy: 0.9331 - loss: 1.0940 - precision: 0.9351 - recall: 0.9788 - val_accuracy: 0.9160 - val_loss: 1.0596 - val_precision: 0.9246 - val_recall: 0.9669 - learning_rate: 1.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 208ms/step - accuracy: 0.9375 - loss: 1.0056 - precision: 0.9396 - recall: 0.9796 - val_accuracy: 0.9159 - val_loss: 0.9883 - val_precision: 0.9237 - val_recall: 0.9678 - learning_rate: 1.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 206ms/step - accuracy: 0.9351 - loss: 0.9395 - precision: 0.9375 - recall: 0.9785 - val_accuracy: 0.9068 - val_loss: 0.9421 - val_precision: 0.9382 - val_recall: 0.9375 - learning_rate: 1.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 187ms/step - accuracy: 0.9392 - loss: 0.8754 - precision: 0.9425 - recall: 0.9786 - val_accuracy: 0.9166 - val_loss: 0.8749 - val_precision: 0.9293 - val_recall: 0.9619 - learning_rate: 1.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 186ms/step - accuracy: 0.9404 - loss: 0.8187 - precision: 0.9428 - recall: 0.9801 - val_accuracy: 0.9146 - val_loss: 0.8291 - val_precision: 0.9328 - val_recall: 0.9550 - learning_rate: 1.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 183ms/step - accuracy: 0.9449 - loss: 0.7658 - precision: 0.9476 - recall: 0.9811 - val_accuracy: 0.9170 - val_loss: 0.7853 - val_precision: 0.9263 - val_recall: 0.9663 - learning_rate: 1.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 183ms/step - accuracy: 0.9445 - loss: 0.7242 - precision: 0.9478 - recall: 0.9798 - val_accuracy: 0.9166 - val_loss: 0.7500 - val_precision: 0.9249 - val_recall: 0.9674 - learning_rate: 1.0000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 185ms/step - accuracy: 0.9461 - loss: 0.6845 - precision: 0.9484 - recall: 0.9818 - val_accuracy: 0.9156 - val_loss: 0.7180 - val_precision: 0.9298 - val_recall: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 185ms/step - accuracy: 0.9487 - loss: 0.6445 - precision: 0.9518 - recall: 0.9813 - val_accuracy: 0.9106 - val_loss: 0.6953 - val_precision: 0.9426 - val_recall: 0.9379 - learning_rate: 1.0000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 184ms/step - accuracy: 0.9512 - loss: 0.6144 - precision: 0.9545 - recall: 0.9815 - val_accuracy: 0.9167 - val_loss: 0.6678 - val_precision: 0.9192 - val_recall: 0.9746 - learning_rate: 1.0000e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 188ms/step - accuracy: 0.9530 - loss: 0.5809 - precision: 0.9559 - recall: 0.9829 - val_accuracy: 0.9122 - val_loss: 0.6426 - val_precision: 0.9352 - val_recall: 0.9486 - learning_rate: 1.0000e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 188ms/step - accuracy: 0.9552 - loss: 0.5532 - precision: 0.9585 - recall: 0.9831 - val_accuracy: 0.9036 - val_loss: 0.6338 - val_precision: 0.9475 - val_recall: 0.9226 - learning_rate: 1.0000e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 192ms/step - accuracy: 0.9573 - loss: 0.5283 - precision: 0.9606 - recall: 0.9833 - val_accuracy: 0.9140 - val_loss: 0.6048 - val_precision: 0.9305 - val_recall: 0.9568 - learning_rate: 1.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 188ms/step - accuracy: 0.9587 - loss: 0.5040 - precision: 0.9620 - recall: 0.9836 - val_accuracy: 0.9141 - val_loss: 0.5868 - val_precision: 0.9303 - val_recall: 0.9572 - learning_rate: 1.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 188ms/step - accuracy: 0.9649 - loss: 0.4776 - precision: 0.9665 - recall: 0.9872 - val_accuracy: 0.9130 - val_loss: 0.5758 - val_precision: 0.9276 - val_recall: 0.9590 - learning_rate: 1.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 189ms/step - accuracy: 0.9666 - loss: 0.4567 - precision: 0.9690 - recall: 0.9872 - val_accuracy: 0.9150 - val_loss: 0.5617 - val_precision: 0.9246 - val_recall: 0.9654 - learning_rate: 1.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 191ms/step - accuracy: 0.9679 - loss: 0.4380 - precision: 0.9708 - recall: 0.9870 - val_accuracy: 0.9127 - val_loss: 0.5534 - val_precision: 0.9408 - val_recall: 0.9430 - learning_rate: 1.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 191ms/step - accuracy: 0.9699 - loss: 0.4190 - precision: 0.9728 - recall: 0.9875 - val_accuracy: 0.9113 - val_loss: 0.5409 - val_precision: 0.9301 - val_recall: 0.9534 - learning_rate: 1.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 189ms/step - accuracy: 0.9732 - loss: 0.4018 - precision: 0.9756 - recall: 0.9888 - val_accuracy: 0.9103 - val_loss: 0.5341 - val_precision: 0.9418 - val_recall: 0.9384 - learning_rate: 1.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 192ms/step - accuracy: 0.9746 - loss: 0.3858 - precision: 0.9773 - recall: 0.9890 - val_accuracy: 0.9170 - val_loss: 0.5379 - val_precision: 0.9240 - val_recall: 0.9690 - learning_rate: 1.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 191ms/step - accuracy: 0.9782 - loss: 0.3678 - precision: 0.9802 - recall: 0.9909 - val_accuracy: 0.9137 - val_loss: 0.5228 - val_precision: 0.9250 - val_recall: 0.9629 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 185ms/step - accuracy: 0.9817 - loss: 0.3525 - precision: 0.9825 - recall: 0.9932 - val_accuracy: 0.9137 - val_loss: 0.5106 - val_precision: 0.9341 - val_recall: 0.9522 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 186ms/step - accuracy: 0.9823 - loss: 0.3402 - precision: 0.9839 - recall: 0.9926 - val_accuracy: 0.9008 - val_loss: 0.5135 - val_precision: 0.9452 - val_recall: 0.9211 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 193ms/step - accuracy: 0.9843 - loss: 0.3277 - precision: 0.9858 - recall: 0.9934 - val_accuracy: 0.9102 - val_loss: 0.5013 - val_precision: 0.9362 - val_recall: 0.9447 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 189ms/step - accuracy: 0.9858 - loss: 0.3142 - precision: 0.9874 - recall: 0.9938 - val_accuracy: 0.9103 - val_loss: 0.4976 - val_precision: 0.9354 - val_recall: 0.9457 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 210ms/step - accuracy: 0.9883 - loss: 0.3006 - precision: 0.9897 - recall: 0.9948 - val_accuracy: 0.9138 - val_loss: 0.5056 - val_precision: 0.9250 - val_recall: 0.9632 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 201ms/step - accuracy: 0.9881 - loss: 0.2929 - precision: 0.9891 - recall: 0.9951 - val_accuracy: 0.9148 - val_loss: 0.4996 - val_precision: 0.9239 - val_recall: 0.9660 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 194ms/step - accuracy: 0.9912 - loss: 0.2785 - precision: 0.9924 - recall: 0.9959 - val_accuracy: 0.9080 - val_loss: 0.4870 - val_precision: 0.9384 - val_recall: 0.9390 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 201ms/step - accuracy: 0.9923 - loss: 0.2704 - precision: 0.9929 - recall: 0.9969 - val_accuracy: 0.9066 - val_loss: 0.4873 - val_precision: 0.9344 - val_recall: 0.9415 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 188ms/step - accuracy: 0.9924 - loss: 0.2618 - precision: 0.9934 - recall: 0.9965 - val_accuracy: 0.9115 - val_loss: 0.4787 - val_precision: 0.9297 - val_recall: 0.9542 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 185ms/step - accuracy: 0.9945 - loss: 0.2522 - precision: 0.9950 - recall: 0.9977 - val_accuracy: 0.9008 - val_loss: 0.4934 - val_precision: 0.9456 - val_recall: 0.9206 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 184ms/step - accuracy: 0.9952 - loss: 0.2439 - precision: 0.9959 - recall: 0.9977 - val_accuracy: 0.9087 - val_loss: 0.4774 - val_precision: 0.9326 - val_recall: 0.9468 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 184ms/step - accuracy: 0.9955 - loss: 0.2364 - precision: 0.9959 - recall: 0.9981 - val_accuracy: 0.9099 - val_loss: 0.4711 - val_precision: 0.9342 - val_recall: 0.9466 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 186ms/step - accuracy: 0.9971 - loss: 0.2284 - precision: 0.9974 - recall: 0.9987 - val_accuracy: 0.9087 - val_loss: 0.4686 - val_precision: 0.9307 - val_recall: 0.9489 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 186ms/step - accuracy: 0.9965 - loss: 0.2229 - precision: 0.9971 - recall: 0.9982 - val_accuracy: 0.9109 - val_loss: 0.4768 - val_precision: 0.9227 - val_recall: 0.9617 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 194ms/step - accuracy: 0.9963 - loss: 0.2174 - precision: 0.9964 - recall: 0.9986 - val_accuracy: 0.9081 - val_loss: 0.4614 - val_precision: 0.9346 - val_recall: 0.9435 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 207ms/step - accuracy: 0.9982 - loss: 0.2097 - precision: 0.9983 - recall: 0.9993 - val_accuracy: 0.9087 - val_loss: 0.4634 - val_precision: 0.9329 - val_recall: 0.9463 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 194ms/step - accuracy: 0.9976 - loss: 0.2039 - precision: 0.9977 - recall: 0.9991 - val_accuracy: 0.9066 - val_loss: 0.4528 - val_precision: 0.9351 - val_recall: 0.9407 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 193ms/step - accuracy: 0.9977 - loss: 0.2001 - precision: 0.9980 - recall: 0.9989 - val_accuracy: 0.9139 - val_loss: 0.4750 - val_precision: 0.9225 - val_recall: 0.9664 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 202ms/step - accuracy: 0.9975 - loss: 0.1956 - precision: 0.9977 - recall: 0.9989 - val_accuracy: 0.9072 - val_loss: 0.4530 - val_precision: 0.9325 - val_recall: 0.9446 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 224ms/step - accuracy: 0.9982 - loss: 0.1902 - precision: 0.9986 - recall: 0.9990 - val_accuracy: 0.9042 - val_loss: 0.4460 - val_precision: 0.9373 - val_recall: 0.9348 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 228ms/step - accuracy: 0.9981 - loss: 0.1853 - precision: 0.9983 - recall: 0.9992 - val_accuracy: 0.9104 - val_loss: 0.4433 - val_precision: 0.9294 - val_recall: 0.9529 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 228ms/step - accuracy: 0.9990 - loss: 0.1801 - precision: 0.9992 - recall: 0.9995 - val_accuracy: 0.9004 - val_loss: 0.4438 - val_precision: 0.9410 - val_recall: 0.9252 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 226ms/step - accuracy: 0.9986 - loss: 0.1766 - precision: 0.9987 - recall: 0.9994 - val_accuracy: 0.9085 - val_loss: 0.4262 - val_precision: 0.9354 - val_recall: 0.9431 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 236ms/step - accuracy: 0.9990 - loss: 0.1718 - precision: 0.9989 - recall: 0.9997 - val_accuracy: 0.9058 - val_loss: 0.4270 - val_precision: 0.9333 - val_recall: 0.9417 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 237ms/step - accuracy: 0.9990 - loss: 0.1688 - precision: 0.9990 - recall: 0.9997 - val_accuracy: 0.9017 - val_loss: 0.4314 - val_precision: 0.9381 - val_recall: 0.9303 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 226ms/step - accuracy: 0.9971 - loss: 0.1697 - precision: 0.9975 - recall: 0.9986 - val_accuracy: 0.9114 - val_loss: 0.4283 - val_precision: 0.9280 - val_recall: 0.9560 - learning_rate: 1.0000e-05\n",
      "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step\n",
      "Accuracy: 0.9236\n",
      "Precision: 0.9721\n",
      "Recall: 0.9460\n",
      "F1 Score: 0.9589\n",
      "ROC AUC Score: 0.9268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAHHCAYAAADTQQDlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABP70lEQVR4nO3deVwU9f8H8NcuyiGyC6iAq4B4oah5luHtTwTPJC1DSVFRO8T7riQ8Kcxbk9QSNf2mVlKiqSgpqWSK4i1eeLtoIaygHML8/uDLfF3RlmWWQ+f17DGPRzvzmc+8ZzN4+/58PjMKQRAEEBEREf0LZVkHQEREROUfEwYiIiIyiAkDERERGcSEgYiIiAxiwkBEREQGMWEgIiIig5gwEBERkUFMGIiIiMggJgxERERkEBMGomdcunQJ3t7eUKvVUCgUiIyMNGn/165dg0KhQEREhEn7fZl16tQJnTp1KuswiOhfMGGgcunKlSv44IMPULt2bVhaWkKlUqFt27ZYsmQJHj9+XKLXDggIwOnTpzF37lxs2LABrVq1KtHrlaYhQ4ZAoVBApVI993u8dOkSFAoFFAoFvvrqK6P7v3PnDkJCQpCQkGCCaImoPKlQ1gEQPWvHjh149913YWFhgcGDB6Nx48bIzs7GwYMHMXnyZJw9exarVq0qkWs/fvwYcXFx+PTTTxEUFFQi13B1dcXjx49RsWLFEunfkAoVKuDRo0fYvn07+vfvr3ds48aNsLS0RGZmZrH6vnPnDmbOnIlatWqhWbNmRT5vz549xboeEZUeJgxUriQlJcHPzw+urq6IiYlB9erVxWOjRo3C5cuXsWPHjhK7/v379wEAtra2JXYNhUIBS0vLEuvfEAsLC7Rt2xb/+c9/CiUMmzZtQs+ePfHTTz+VSiyPHj1CpUqVYG5uXirXI6Li45AElSthYWFIT0/Ht99+q5csFKhbty7Gjh0rfn7y5Almz56NOnXqwMLCArVq1cInn3yCrKwsvfNq1aqFXr164eDBg3jjjTdgaWmJ2rVrY/369WKbkJAQuLq6AgAmT54MhUKBWrVqAcgv5Rf8+9NCQkKgUCj09kVHR6Ndu3awtbVF5cqV4e7ujk8++UQ8/qI5DDExMWjfvj2sra1ha2uLPn364Pz588+93uXLlzFkyBDY2tpCrVZj6NChePTo0Yu/2GcMHDgQv/32G1JTU8V9R48exaVLlzBw4MBC7VNSUjBp0iQ0adIElStXhkqlQvfu3XHy5Emxzf79+/H6668DAIYOHSoObRTcZ6dOndC4cWPEx8ejQ4cOqFSpkvi9PDuHISAgAJaWloXu38fHB3Z2drhz506R75WITIMJA5Ur27dvR+3atdGmTZsitR8+fDiCg4PRokULLFq0CB07dkRoaCj8/PwKtb18+TLeeecddO3aFQsWLICdnR2GDBmCs2fPAgD69u2LRYsWAQAGDBiADRs2YPHixUbFf/bsWfTq1QtZWVmYNWsWFixYgLfeeguHDh361/P27t0LHx8f3Lt3DyEhIZgwYQIOHz6Mtm3b4tq1a4Xa9+/fHw8fPkRoaCj69++PiIgIzJw5s8hx9u3bFwqFAj///LO4b9OmTWjQoAFatGhRqP3Vq1cRGRmJXr16YeHChZg8eTJOnz6Njh07ir+8GzZsiFmzZgEARo4ciQ0bNmDDhg3o0KGD2M8///yD7t27o1mzZli8eDE6d+783PiWLFmCatWqISAgALm5uQCAb775Bnv27MGyZcug0WiKfK9EZCICUTmRlpYmABD69OlTpPYJCQkCAGH48OF6+ydNmiQAEGJiYsR9rq6uAgAhNjZW3Hfv3j3BwsJCmDhxorgvKSlJACDMnz9fr8+AgADB1dW1UAyff/658PT/RosWLRIACPfv339h3AXXWLt2rbivWbNmgoODg/DPP/+I+06ePCkolUph8ODBha43bNgwvT7ffvttoUqVKi+85tP3YW1tLQiCILzzzjtCly5dBEEQhNzcXMHJyUmYOXPmc7+DzMxMITc3t9B9WFhYCLNmzRL3HT16tNC9FejYsaMAQAgPD3/usY4dO+rt2717twBAmDNnjnD16lWhcuXKgq+vr8F7JKKSwQoDlRs6nQ4AYGNjU6T2O3fuBABMmDBBb//EiRMBoNBcBw8PD7Rv3178XK1aNbi7u+Pq1avFjvlZBXMffvnlF+Tl5RXpnLt37yIhIQFDhgyBvb29uP+1115D165dxft82ocffqj3uX379vjnn3/E77AoBg4ciP3790Or1SImJgZarfa5wxFA/rwHpTL/x0Vubi7++ecfcbjl+PHjRb6mhYUFhg4dWqS23t7e+OCDDzBr1iz07dsXlpaW+Oabb4p8LSIyLSYMVG6oVCoAwMOHD4vU/vr161Aqlahbt67eficnJ9ja2uL69et6+11cXAr1YWdnhwcPHhQz4sLee+89tG3bFsOHD4ejoyP8/PywZcuWf00eCuJ0d3cvdKxhw4b4+++/kZGRobf/2Xuxs7MDAKPupUePHrCxscHmzZuxceNGvP7664W+ywJ5eXlYtGgR6tWrBwsLC1StWhXVqlXDqVOnkJaWVuRr1qhRw6gJjl999RXs7e2RkJCApUuXwsHBocjnEpFpMWGgckOlUkGj0eDMmTNGnffspMMXMTMze+5+QRCKfY2C8fUCVlZWiI2Nxd69ezFo0CCcOnUK7733Hrp27VqorRRS7qWAhYUF+vbti3Xr1mHbtm0vrC4AwLx58zBhwgR06NAB33//PXbv3o3o6Gg0atSoyJUUIP/7McaJEydw7949AMDp06eNOpeITIsJA5UrvXr1wpUrVxAXF2ewraurK/Ly8nDp0iW9/cnJyUhNTRVXPJiCnZ2d3oqCAs9WMQBAqVSiS5cuWLhwIc6dO4e5c+ciJiYGv//++3P7LogzMTGx0LELFy6gatWqsLa2lnYDLzBw4ECcOHECDx8+fO5E0QI//vgjOnfujG+//RZ+fn7w9vaGl5dXoe+kqMlbUWRkZGDo0KHw8PDAyJEjERYWhqNHj5qsfyIyDhMGKlemTJkCa2trDB8+HMnJyYWOX7lyBUuWLAGQX1IHUGglw8KFCwEAPXv2NFlcderUQVpaGk6dOiXuu3v3LrZt26bXLiUlpdC5BQ8wenapZ4Hq1aujWbNmWLdund4v4DNnzmDPnj3ifZaEzp07Y/bs2Vi+fDmcnJxe2M7MzKxQ9WLr1q24ffu23r6CxOZ5yZWxpk6dihs3bmDdunVYuHAhatWqhYCAgBd+j0RUsvjgJipX6tSpg02bNuG9995Dw4YN9Z70ePjwYWzduhVDhgwBADRt2hQBAQFYtWoVUlNT0bFjR/z1119Yt24dfH19X7hkrzj8/PwwdepUvP322xgzZgwePXqElStXon79+nqT/mbNmoXY2Fj07NkTrq6uuHfvHr7++mvUrFkT7dq1e2H/8+fPR/fu3eHp6YnAwEA8fvwYy5Ytg1qtRkhIiMnu41lKpRKfffaZwXa9evXCrFmzMHToULRp0wanT5/Gxo0bUbt2bb12derUga2tLcLDw2FjYwNra2u0bt0abm5uRsUVExODr7/+Gp9//rm4zHPt2rXo1KkTZsyYgbCwMKP6IyITKONVGkTPdfHiRWHEiBFCrVq1BHNzc8HGxkZo27atsGzZMiEzM1Nsl5OTI8ycOVNwc3MTKlasKDg7OwvTp0/XayMI+csqe/bsWeg6zy7ne9GySkEQhD179giNGzcWzM3NBXd3d+H7778vtKxy3759Qp8+fQSNRiOYm5sLGo1GGDBggHDx4sVC13h26eHevXuFtm3bClZWVoJKpRJ69+4tnDt3Tq9NwfWeXba5du1aAYCQlJT0wu9UEPSXVb7Ii5ZVTpw4UahevbpgZWUltG3bVoiLi3vucshffvlF8PDwECpUqKB3nx07dhQaNWr03Gs+3Y9OpxNcXV2FFi1aCDk5OXrtxo8fLyiVSiEuLu5f74GITE8hCEbMkiIiIiJZ4hwGIiIiMogJAxERERnEhIGIiIgMYsJAREREBjFhICIiIoOYMBAREZFBL/WDm/Ly8nDnzh3Y2NiY9JG0RERUOgRBwMOHD6HRaMQ3opaEzMxMZGdnS+7H3NwclpaWJojo5fNSJwx37tyBs7NzWYdBREQS3bx5EzVr1iyRvjMzM2FlUwV48khyX05OTkhKSpJl0vBSJww2NjYAgItXb8DGRlXG0RCVDKWS1TN6dT3U6VDXzVn8eV4SsrOzgSePYOERAJgV/fXqheRmQ3tuHbKzs5kwvGwKhiFsbFRQqZgw0KuJCQPJQakMK1ewhEJCwiAo5D3t76VOGIiIiIpMAUBKYiLz3J0JAxERyYNCmb9JOV/G5H33REREVCSsMBARkTwoFBKHJOQ9JsGEgYiI5IFDEpLI++6JiIioSFhhICIieeCQhCRMGIiISCYkDknIvCgv77snIiKiImGFgYiI5IFDEpIwYSAiInngKglJ5H33REREVCSsMBARkTxwSEISJgxERCQPHJKQhAkDERHJAysMksg7XSIiIqIiYYWBiIjkgUMSkjBhICIieVAoJCYMHJIgIiIi+lesMBARkTwoFfmblPNljAkDERHJA+cwSCLvuyciIiohsbGx6N27NzQaDRQKBSIjI1/Y9sMPP4RCocDixYv19qekpMDf3x8qlQq2trYIDAxEenq6XptTp06hffv2sLS0hLOzM8LCwgr1v3XrVjRo0ACWlpZo0qQJdu7cafT9MGEgIiJ5KHgOg5TNCBkZGWjatClWrFjxr+22bduGP//8ExqNptAxf39/nD17FtHR0YiKikJsbCxGjhwpHtfpdPD29oarqyvi4+Mxf/58hISEYNWqVWKbw4cPY8CAAQgMDMSJEyfg6+sLX19fnDlzxqj74ZAEERHJQykPSXTv3h3du3f/1za3b9/G6NGjsXv3bvTs2VPv2Pnz57Fr1y4cPXoUrVq1AgAsW7YMPXr0wFdffQWNRoONGzciOzsb3333HczNzdGoUSMkJCRg4cKFYmKxZMkSdOvWDZMnTwYAzJ49G9HR0Vi+fDnCw8OLfD+sMBAREZWBvLw8DBo0CJMnT0ajRo0KHY+Li4Otra2YLACAl5cXlEoljhw5Irbp0KEDzM3NxTY+Pj5ITEzEgwcPxDZeXl56ffv4+CAuLs6oeFlhICIieTDRo6F1Op3ebgsLC1hYWBjd3ZdffokKFSpgzJgxzz2u1Wrh4OCgt69ChQqwt7eHVqsV27i5uem1cXR0FI/Z2dlBq9WK+55uU9BHUbHCQERE8lAwJCFlA+Ds7Ay1Wi1uoaGhRocSHx+PJUuWICIiAoqX5IFQrDAQEZE8mKjCcPPmTahUKnF3caoLf/zxB+7duwcXFxdxX25uLiZOnIjFixfj2rVrcHJywr179/TOe/LkCVJSUuDk5AQAcHJyQnJysl6bgs+G2hQcLypWGIiIiIygUqn0tuIkDIMGDcKpU6eQkJAgbhqNBpMnT8bu3bsBAJ6enkhNTUV8fLx4XkxMDPLy8tC6dWuxTWxsLHJycsQ20dHRcHd3h52dndhm3759etePjo6Gp6enUTGzwkBERPJQyqsk0tPTcfnyZfFzUlISEhISYG9vDxcXF1SpUkWvfcWKFeHk5AR3d3cAQMOGDdGtWzeMGDEC4eHhyMnJQVBQEPz8/MQlmAMHDsTMmTMRGBiIqVOn4syZM1iyZAkWLVok9jt27Fh07NgRCxYsQM+ePfHDDz/g2LFjeksvi4IVBiIikodSfg7DsWPH0Lx5czRv3hwAMGHCBDRv3hzBwcFF7mPjxo1o0KABunTpgh49eqBdu3Z6v+jVajX27NmDpKQktGzZEhMnTkRwcLDesxratGmDTZs2YdWqVWjatCl+/PFHREZGonHjxkbdj0IQBMGoM8oRnU4HtVqNu/dT9caTiF4lSpk/v55ebTqdDo5V1EhLSyuxn+MFvyssvOZBUcGy2P0ITzKRtfeTEo21POOQBBERyYTEIQmZF+WZMBARkTyYaJWEXMk7XSIiIqIiYYWBiIjkQaGQuEpC3hUGJgxERCQPpbys8lUj77snIiKiImGFgYiI5IGTHiVhwkBERPLAIQlJmDAQEZE8sMIgibzTJSIiIioSVhiIiEgeOCQhCRMGIiKSBw5JSCLvdImIiIiKhBUGIiKSBYVCAQUrDMXGhIGIiGSBCYM0HJIgIiIig1hhICIieVD8d5NyvowxYSAiIlngkIQ0HJIgIiIig1hhICIiWWCFQRomDEREJAtMGKRhwkBERLLAhEEazmEgIiIig1hhICIieeCySkmYMBARkSxwSEIaDkkQERGRQawwEBGRLOS/3VpKhcF0sbyMmDAQEZEsKCBxSELmGQOHJIiIiMggVhiIiEgWOOlRGiYMREQkD1xWKQmHJIiIiMggVhiIiEgeJA5JCBySICIievVJncMgbYXFy48JAxERyQITBmk4h4GIiIgMYoWBiIjkgaskJGHCQEREssAhCWk4JEFEREQGscJARESywAqDNKwwEBGRLBQkDFI2Y8TGxqJ3797QaDRQKBSIjIwUj+Xk5GDq1Klo0qQJrK2todFoMHjwYNy5c0evj5SUFPj7+0OlUsHW1haBgYFIT0/Xa3Pq1Cm0b98elpaWcHZ2RlhYWKFYtm7digYNGsDS0hJNmjTBzp07jboXgAkDERFRicjIyEDTpk2xYsWKQscePXqE48ePY8aMGTh+/Dh+/vlnJCYm4q233tJr5+/vj7NnzyI6OhpRUVGIjY3FyJEjxeM6nQ7e3t5wdXVFfHw85s+fj5CQEKxatUpsc/jwYQwYMACBgYE4ceIEfH194evrizNnzhh1PwpBEAQjv4NyQ6fTQa1W4+79VKhUqrIOh6hEKJXyLoPSq02n08GxihppaWkl9nO84HeF45ANUJpXKnY/edmPkBwxqFixKhQKbNu2Db6+vi9sc/ToUbzxxhu4fv06XFxccP78eXh4eODo0aNo1aoVAGDXrl3o0aMHbt26BY1Gg5UrV+LTTz+FVquFubk5AGDatGmIjIzEhQsXAADvvfceMjIyEBUVJV7rzTffRLNmzRAeHl7ke2CFgYiI5EFhgg35CcjTW1ZWlknCS0tLg0KhgK2tLQAgLi4Otra2YrIAAF5eXlAqlThy5IjYpkOHDmKyAAA+Pj5ITEzEgwcPxDZeXl561/Lx8UFcXJxR8TFhICIiMoKzszPUarW4hYaGSu4zMzMTU6dOxYABA8TqhVarhYODg167ChUqwN7eHlqtVmzj6Oio16bgs6E2BceLiqskiIhIFky1SuLmzZt6QxIWFhaS4srJyUH//v0hCAJWrlwpqa+SxISBiIhkwVQJg0qlMtl8i4Jk4fr164iJidHr18nJCffu3dNr/+TJE6SkpMDJyUlsk5ycrNem4LOhNgXHi4pDEkREJAulvazSkIJk4dKlS9i7dy+qVKmid9zT0xOpqamIj48X98XExCAvLw+tW7cW28TGxiInJ0dsEx0dDXd3d9jZ2Ylt9u3bp9d3dHQ0PD09jYqXCQMREVEJSE9PR0JCAhISEgAASUlJSEhIwI0bN5CTk4N33nkHx44dw8aNG5GbmwutVgutVovs7GwAQMOGDdGtWzeMGDECf/31Fw4dOoSgoCD4+flBo9EAAAYOHAhzc3MEBgbi7Nmz2Lx5M5YsWYIJEyaIcYwdOxa7du3CggULcOHCBYSEhODYsWMICgoy6n64rJKonOOySnqVleaySs2ITZKXVd5ZPbDIse7fvx+dO3cutD8gIAAhISFwc3N77nm///47OnXqBCD/wU1BQUHYvn07lEol+vXrh6VLl6Jy5cpi+1OnTmHUqFE4evQoqlatitGjR2Pq1Kl6fW7duhWfffYZrl27hnr16iEsLAw9evQw4u6ZMBCVe0wY6FVWmglDjZH/kZww3F41oERjLc84JEFEREQGcZWEzH25eifC1vymt6+uqwOObJkhfj56OglzVm7H8bPXoVQq0aR+DWxd8jGsLPMfFNLM93PcvJui18eMj3tjXIB3yd8AkZEWRezBrBW/4kO/Tgid+A4AYNy8/+DAX4nQ/p0GaysLvPGaG0JG90H9Wv+bRW73euHx3jVzh6Cfd6tC+6l84sunpCkXCcOKFSswf/58aLVaNG3aFMuWLcMbb7xR1mHJRoPa1fHz8v/9MKxg9r/C09HTSXh37NcYF9AVX056F2ZmSpy9dLtQmXz6yJ4Y5NtG/Fy5krR1yUQl4fjZ64jYdgiN6tXQ29+sgTPe7fY6nJ3s8ED3CF+s2oG+QStw8peZMHvq/4cVwe+ji6eH+FltY1VqsZN0CkhMGMCEoUxt3rwZEyZMQHh4OFq3bo3FixeLj7V89glXVDIqmCnhWOX543GfLvoZI/t31KsW1HN1LNSuciWLF/ZBVB6kP8rCyOAILPlkAL76bpfesSF924n/7qKpgk8/6o32A0Nx4+4/cKtZTTymtrGCY1X+OSd5KvM5DAsXLsSIESMwdOhQeHh4IDw8HJUqVcJ3331X1qHJxtWb9+HR81O0eDsEHwSvwy1t/vDC/ZSHiD97DVXtbdBt+EI06PYJen+4BH8mXCnUx5L10ajbdSo6DfoSyzbsxZMnuaV9G0T/anLYZni3bYxOrRv8a7uMx1nYtP1PuGqqoIaj3TN9bEEdr6noEjAf3/8ah5d4zrgslbfnMLxsyrTCkJ2djfj4eEyfPl3cp1Qq4eXlZfRLMah4WjZyxfLg91HXxQHJ/+gQtuY39PxgMQ5u+gTXbv8NAAhbvRMzx7yNJvVrYPPOv/B20HIc3DQddVzyK0Aj+3fEa+7OsFNVwl+nkzD761+R/I8Oc8b1LctbIxL9tOcYTl64iZh1U17YZs3WWIQsi0TG42zUc3XEthVBMK/4vx+Rn3zQE+1fr49KluaI+fMCJn25GRmPsvCBX6dSuAMyiadeIFXs82WsTBOGv//+G7m5uc99KUbBazmflpWVpfdWMJ1OV+Ixvuq82jQS/71RvRpo2cgVTft8jl/2nUD9Wvn/XQLebgv/3m8CAF5zd0bssYvYuP1PBI/Kf2/7xwP/T68P8wpmmPDFD5jxcW9YmFcsxbshKuyW9gGmL/gJPy8PgqXFi/88vtv9dXRu3QDav3VY/v1eDJ3+HXatmSCeM3l4d7Hta+7OePQ4C0s37GXCQLJR5kMSxggNDdV7Q5izs3NZh/TKUdtUQh0XB1y9eV8cq3V3q67Xpn4tR9xOfvDCPlo2roUnuXm48czKCaKycPLCDdxPeYhOg75E1TfHoOqbY3Do+GV8s/kAqr45Brm5eQAAdWUr1HFxQNsWdbHuy+G4dC0ZUftPvrDflo1r4c69VGRl57ywDZUvHJKQpkwrDFWrVoWZmVmRX4oxffp0vcdd6nQ6Jg0mlv4oC9du/43+3V+HS/UqcKqmxuXr+v99rty4jy6eDV/Yx+mLt6BUKlDNzqakwyUyqMPr7jj0n0/09gXN+h71ajli7OCueqsgCgiCAEEQkJ395IX9nr54C7aqSqyivUS4rFKaMk0YzM3N0bJlS+zbtw++vr4AgLy8POzbt++5z7i2sLCQ/BpR0he8ZBt82jeGs5M9tH+n4YvVO2GmVKKfd0soFAqM9u+CL1bvRON6NdC4fk38sOMILl1PxtrQYQDyl13Gn7mGdi3robK1JY6eTsJni3/Gu91eh62q+E9UIzIVG2tLeNTV6O2rZGUOe7U1POpqcO3W3/g5Oh7/92ZDVLGrjDvJqVi8bg8sLSuia9v8IbvfYk/jfspDtGpcC5YWFfH7kQtYtHYPgt7vUha3RMWkUORvUs6XszJfVjlhwgQEBASgVatWeOONN7B48WJkZGRg6NChZR2aLNy5l4oRMyLwIO0RqthWxptNa2P3txNQ9b/VgQ8HdEZmdg4+XfwzUnWP0KheDfy0dJS41My8YgX8HH0cX675Ddk5T+BSvQo+9OuMjwcWfn46UXlkYVEBcQlXEP7DfqTqHqGavQ3aNK+L3Wsmopp9/v8HFSuYYc3WWHy66CcIggC3mtUwZ3xfBDz17BGiV125eJfE8uXLxQc3NWvWDEuXLhVf3flv+C4JkgO+S4JeZaX5Lonao3+E0sK62P3kZWXg6rJ3ZPsuiTKvMABAUFCQ0a/ZJCIiMorEIQm5L6t8qVZJEBERUdkoFxUGIiKiksZVEtIwYSAiIlngKglpOCRBREREBrHCQEREsqBUKiStOhJkvmKJCQMREckChySk4ZAEERERGcQKAxERyQJXSUjDhIGIiGSBQxLSMGEgIiJZYIVBGs5hICIiIoNYYSAiIllghUEaJgxERCQLnMMgDYckiIiIyCBWGIiISBYUkDgkIfP3WzNhICIiWeCQhDQckiAiIiKDWGEgIiJZ4CoJaZgwEBGRLHBIQhoOSRAREZFBrDAQEZEscEhCGiYMREQkCxySkIYJAxERyQIrDNJwDgMREREZxAoDERHJg8QhCZk/6JEJAxERyQOHJKThkAQREVEJiI2NRe/evaHRaKBQKBAZGal3XBAEBAcHo3r16rCysoKXlxcuXbqk1yYlJQX+/v5QqVSwtbVFYGAg0tPT9dqcOnUK7du3h6WlJZydnREWFlYolq1bt6JBgwawtLREkyZNsHPnTqPvhwkDERHJQsEqCSmbMTIyMtC0aVOsWLHiucfDwsKwdOlShIeH48iRI7C2toaPjw8yMzPFNv7+/jh79iyio6MRFRWF2NhYjBw5Ujyu0+ng7e0NV1dXxMfHY/78+QgJCcGqVavENocPH8aAAQMQGBiIEydOwNfXF76+vjhz5oxx358gCIJxX0H5odPpoFarcfd+KlQqVVmHQ1QilEp5l0Hp1abT6eBYRY20tLQS+zle8LvijVm/oYKldbH7eZKZgb+CuxcrVoVCgW3btsHX1xdAfnVBo9Fg4sSJmDRpEgAgLS0Njo6OiIiIgJ+fH86fPw8PDw8cPXoUrVq1AgDs2rULPXr0wK1bt6DRaLBy5Up8+umn0Gq1MDc3BwBMmzYNkZGRuHDhAgDgvffeQ0ZGBqKiosR43nzzTTRr1gzh4eFFvgdWGIiIiIyg0+n0tqysLKP7SEpKglarhZeXl7hPrVajdevWiIuLAwDExcXB1tZWTBYAwMvLC0qlEkeOHBHbdOjQQUwWAMDHxweJiYl48OCB2Obp6xS0KbhOUTFhICIiWTDVkISzszPUarW4hYaGGh2LVqsFADg6Ourtd3R0FI9ptVo4ODjoHa9QoQLs7e312jyvj6ev8aI2BceLiqskiIhIFky1SuLmzZt6QxIWFhaSY3sZsMJARERkBJVKpbcVJ2FwcnICACQnJ+vtT05OFo85OTnh3r17esefPHmClJQUvTbP6+Ppa7yoTcHxomLCQEREslBQYZCymYqbmxucnJywb98+cZ9Op8ORI0fg6ekJAPD09ERqairi4+PFNjExMcjLy0Pr1q3FNrGxscjJyRHbREdHw93dHXZ2dmKbp69T0KbgOkXFhIGIiGShtJdVpqenIyEhAQkJCQDyJzomJCTgxo0bUCgUGDduHObMmYNff/0Vp0+fxuDBg6HRaMSVFA0bNkS3bt0wYsQI/PXXXzh06BCCgoLg5+cHjUYDABg4cCDMzc0RGBiIs2fPYvPmzViyZAkmTJggxjF27Fjs2rULCxYswIULFxASEoJjx44hKCjIqPvhHAYiIpKF0n7S47Fjx9C5c2fxc8Ev8YCAAERERGDKlCnIyMjAyJEjkZqainbt2mHXrl2wtLQUz9m4cSOCgoLQpUsXKJVK9OvXD0uXLhWPq9Vq7NmzB6NGjULLli1RtWpVBAcH6z2roU2bNti0aRM+++wzfPLJJ6hXrx4iIyPRuHFj4+6fz2EgKt/4HAZ6lZXmcxjahu6R/ByGQ9O9SzTW8owVBiIikoXiDCs8e76cMWEgIiJZ4MunpOGkRyIiIjKIFQYiIpIFBSQOSZgskpcTEwYiIpIFpUIBpYSMQcq5rwIOSRAREZFBrDAQEZEscJWENEwYiIhIFrhKQhomDEREJAtKRf4m5Xw54xwGIiIiMogVBiIikgeFxGEFmVcYmDAQEZEscNKjNBySICIiIoNYYSAiIllQ/PcfKefLGRMGIiKSBa6SkIZDEkRERGQQKwxERCQLfHCTNEVKGH799dcid/jWW28VOxgiIqKSwlUS0hQpYfD19S1SZwqFArm5uVLiISIionKoSAlDXl5eScdBRERUovh6a2kkzWHIzMyEpaWlqWIhIiIqMRySkMboVRK5ubmYPXs2atSogcqVK+Pq1asAgBkzZuDbb781eYBERESmUDDpUcomZ0YnDHPnzkVERATCwsJgbm4u7m/cuDHWrFlj0uCIiIiofDA6YVi/fj1WrVoFf39/mJmZifubNm2KCxcumDQ4IiIiUykYkpCyyZnRcxhu376NunXrFtqfl5eHnJwckwRFRERkapz0KI3RFQYPDw/88ccfhfb/+OOPaN68uUmCIiIiovLF6ApDcHAwAgICcPv2beTl5eHnn39GYmIi1q9fj6ioqJKIkYiISDLFfzcp58uZ0RWGPn36YPv27di7dy+sra0RHByM8+fPY/v27ejatWtJxEhERCQZV0lIU6znMLRv3x7R0dGmjoWIiIjKqWI/uOnYsWM4f/48gPx5DS1btjRZUERERKbG11tLY3TCcOvWLQwYMACHDh2Cra0tACA1NRVt2rTBDz/8gJo1a5o6RiIiIsn4tkppjJ7DMHz4cOTk5OD8+fNISUlBSkoKzp8/j7y8PAwfPrwkYiQiIqIyZnSF4cCBAzh8+DDc3d3Ffe7u7li2bBnat29v0uCIiIhMSeZFAkmMThicnZ2f+4Cm3NxcaDQakwRFRERkahySkMboIYn58+dj9OjROHbsmLjv2LFjGDt2LL766iuTBkdERGQqBZMepWxyVqQKg52dnV5mlZGRgdatW6NChfzTnzx5ggoVKmDYsGHw9fUtkUCJiIio7BQpYVi8eHEJh0FERFSyOCQhTZEShoCAgJKOg4iIqETx0dDSFPvBTQCQmZmJ7OxsvX0qlUpSQERERFT+GD3pMSMjA0FBQXBwcIC1tTXs7Oz0NiIiovKo4PXWUjZj5ObmYsaMGXBzc4OVlRXq1KmD2bNnQxAEsY0gCAgODkb16tVhZWUFLy8vXLp0Sa+flJQU+Pv7Q6VSwdbWFoGBgUhPT9drc+rUKbRv3x6WlpZwdnZGWFhY8b+oFzA6YZgyZQpiYmKwcuVKWFhYYM2aNZg5cyY0Gg3Wr19v8gCJiIhMQaGQvhnjyy+/xMqVK7F8+XKcP38eX375JcLCwrBs2TKxTVhYGJYuXYrw8HAcOXIE1tbW8PHxQWZmptjG398fZ8+eRXR0NKKiohAbG4uRI0eKx3U6Hby9veHq6or4+HjMnz8fISEhWLVqleTv7GkK4elUpwhcXFywfv16dOrUCSqVCsePH0fdunWxYcMG/Oc//8HOnTtNGuC/0el0UKvVuHs/lUMh9MpSyn0tF73SdDodHKuokZaWVmI/xwt+VwxeGwfzSpWL3U/2o3SsH+pZ5Fh79eoFR0dHfPvtt+K+fv36wcrKCt9//z0EQYBGo8HEiRMxadIkAEBaWhocHR0REREBPz8/nD9/Hh4eHjh69ChatWoFANi1axd69OiBW7duQaPRYOXKlfj000+h1Wphbm4OAJg2bRoiIyNx4cKFYt/vs4yuMKSkpKB27doA8ucrpKSkAADatWuH2NhYkwVGRERkSqX9eus2bdpg3759uHjxIgDg5MmTOHjwILp37w4ASEpKglarhZeXl3iOWq1G69atERcXBwCIi4uDra2tmCwAgJeXF5RKJY4cOSK26dChg5gsAICPjw8SExPx4MGD4n1Zz2H0pMfatWsjKSkJLi4uaNCgAbZs2YI33ngD27dvF19GRUREVN4UZ1jh2fOB/IrF0ywsLGBhYVGo/bRp06DT6dCgQQOYmZkhNzcXc+fOhb+/PwBAq9UCABwdHfXOc3R0FI9ptVo4ODjoHa9QoQLs7e312ri5uRXqo+CYqeYXGl1hGDp0KE6ePAkg/8tYsWIFLC0tMX78eEyePNkkQREREZVXzs7OUKvV4hYaGvrcdlu2bMHGjRuxadMmHD9+HOvWrcNXX32FdevWlXLEpmF0hWH8+PHiv3t5eeHChQuIj49H3bp18dprr5k0OCIiIlMpzkqHZ88HgJs3b+rNYXhedQEAJk+ejGnTpsHPzw8A0KRJE1y/fh2hoaEICAiAk5MTACA5ORnVq1cXz0tOTkazZs0AAE5OTrh3755ev0+ePEFKSop4vpOTE5KTk/XaFHwuaGMKRlcYnuXq6oq+ffsyWSAionLNVKskVCqV3vaihOHRo0dQKvV/zZqZmSEvLw8A4ObmBicnJ+zbt088rtPpcOTIEXh6egIAPD09kZqaivj4eLFNTEwM8vLy0Lp1a7FNbGys3osho6Oj4e7ubtLHHRSpwrB06dIidzhmzJhiB0NERFRSSvvR0L1798bcuXPh4uKCRo0a4cSJE1i4cCGGDRsm9jdu3DjMmTMH9erVg5ubG2bMmAGNRiO+l6lhw4bo1q0bRowYgfDwcOTk5CAoKAh+fn7iG6IHDhyImTNnIjAwEFOnTsWZM2ewZMkSLFq0qNj3+jxFShiKelGFQsGEgYiICMCyZcswY8YMfPzxx7h37x40Gg0++OADBAcHi22mTJmCjIwMjBw5EqmpqWjXrh127doFS0tLsc3GjRsRFBSELl26QKlUol+/fnp/kVer1dizZw9GjRqFli1bomrVqggODtZ7VoMpGP0chvKkYG3tzeQHfA4DvbIcPZmE06tLyM1G1unVpfIchpHf/yX5OQyr3n+jRGMtzyS9S4KIiOhlwbdVSiN50iMRERG9+lhhICIiWVAoAClPWpd5gYEJAxERyYNSYsIg99e6cEiCiIiIDCpWwvDHH3/g/fffh6enJ27fvg0A2LBhAw4ePGjS4IiIiEyltF8+9aoxOmH46aef4OPjAysrK5w4cQJZWVkA8l/JOW/ePJMHSEREZAoFQxJSNjkzOmGYM2cOwsPDsXr1alSsWFHc37ZtWxw/ftykwREREVH5YPSkx8TERHTo0KHQfrVajdTUVFPEREREZHKmer21XBldYXBycsLly5cL7T948CBq165tkqCIiIhMreBtlVI2OTM6YRgxYgTGjh2LI0eOQKFQ4M6dO9i4cSMmTZqEjz76qCRiJCIikkxpgk3OjB6SmDZtGvLy8tClSxc8evQIHTp0gIWFBSZNmoTRo0eXRIxERERUxoxOGBQKBT799FNMnjwZly9fRnp6Ojw8PFC5cvFf6EFERFTSOIdBmmI/6dHc3BweHh6mjIWIiKjEKCFtHoIS8s4YjE4YOnfu/K8Pr4iJiZEUEBEREZU/RicMzZo10/uck5ODhIQEnDlzBgEBAaaKi4iIyKQ4JCGN0QnDokWLnrs/JCQE6enpkgMiIiIqCXz5lDQmWyXy/vvv47vvvjNVd0RERFSOmOz11nFxcbC0tDRVd0RERCalUEDSpEcOSRipb9++ep8FQcDdu3dx7NgxzJgxw2SBERERmRLnMEhjdMKgVqv1PiuVSri7u2PWrFnw9vY2WWBERERUfhiVMOTm5mLo0KFo0qQJ7OzsSiomIiIik+OkR2mMmvRoZmYGb29vvpWSiIheOgoT/CNnRq+SaNy4Ma5evVoSsRAREZWYggqDlE3OjE4Y5syZg0mTJiEqKgp3796FTqfT24iIiOjVU+Q5DLNmzcLEiRPRo0cPAMBbb72l94hoQRCgUCiQm5tr+iiJiIgk4hwGaYqcMMycORMffvghfv/995KMh4iIqEQoFIp/fRdSUc6XsyInDIIgAAA6duxYYsEQERFR+WTUskq5Z1dERPTy4pCENEYlDPXr1zeYNKSkpEgKiIiIqCTwSY/SGJUwzJw5s9CTHomIiOjVZ1TC4OfnBwcHh5KKhYiIqMQoFQpJL5+Scu6roMgJA+cvEBHRy4xzGKQp8oObClZJEBERkfwUucKQl5dXknEQERGVLImTHmX+KgnjX29NRET0MlJCAaWE3/pSzn0VMGEgIiJZ4LJKaYx++RQRERHJDysMREQkC1wlIQ0TBiIikgU+h0EaDkkQERGVkNu3b+P9999HlSpVYGVlhSZNmuDYsWPicUEQEBwcjOrVq8PKygpeXl64dOmSXh8pKSnw9/eHSqWCra0tAgMDkZ6ertfm1KlTaN++PSwtLeHs7IywsDCT3wsTBiIikoWCSY9SNmM8ePAAbdu2RcWKFfHbb7/h3LlzWLBgAezs7MQ2YWFhWLp0KcLDw3HkyBFYW1vDx8cHmZmZYht/f3+cPXsW0dHRiIqKQmxsLEaOHCke1+l08Pb2hqurK+Lj4zF//nyEhIRg1apVkr+zp3FIgoiIZEEJiUMSRi6r/PLLL+Hs7Iy1a9eK+9zc3MR/FwQBixcvxmeffYY+ffoAANavXw9HR0dERkbCz88P58+fx65du3D06FG0atUKALBs2TL06NEDX331FTQaDTZu3Ijs7Gx89913MDc3R6NGjZCQkICFCxfqJRZSscJARERkBJ1Op7dlZWU9t92vv/6KVq1a4d1334WDgwOaN2+O1atXi8eTkpKg1Wrh5eUl7lOr1WjdujXi4uIAAHFxcbC1tRWTBQDw8vKCUqnEkSNHxDYdOnSAubm52MbHxweJiYl48OCBye6bCQMREcmCqYYknJ2doVarxS00NPS517t69SpWrlyJevXqYffu3fjoo48wZswYrFu3DgCg1WoBAI6OjnrnOTo6ise0Wm2hlz5WqFAB9vb2em2e18fT1zAFDkkQEZEsKCHtb8kF5968eRMqlUrcb2Fh8dz2eXl5aNWqFebNmwcAaN68Oc6cOYPw8HAEBARIiKRssMJARERkBJVKpbe9KGGoXr06PDw89PY1bNgQN27cAAA4OTkBAJKTk/XaJCcni8ecnJxw7949veNPnjxBSkqKXpvn9fH0NUyBCQMREcmCQqGQvBmjbdu2SExM1Nt38eJFuLq6AsifAOnk5IR9+/aJx3U6HY4cOQJPT08AgKenJ1JTUxEfHy+2iYmJQV5eHlq3bi22iY2NRU5OjtgmOjoa7u7ueisypGLCQEREsqAwwWaM8ePH488//8S8efNw+fJlbNq0CatWrcKoUaPy41EoMG7cOMyZMwe//vorTp8+jcGDB0Oj0cDX1xdAfkWiW7duGDFiBP766y8cOnQIQUFB8PPzg0ajAQAMHDgQ5ubmCAwMxNmzZ7F582YsWbIEEyZMkPBtFcY5DEREJAul/aTH119/Hdu2bcP06dMxa9YsuLm5YfHixfD39xfbTJkyBRkZGRg5ciRSU1PRrl077Nq1C5aWlmKbjRs3IigoCF26dIFSqUS/fv2wdOlS8bharcaePXswatQotGzZElWrVkVwcLBJl1QCgEIQBMGkPZYinU4HtVqNm8kP9CagEL1KHD3HlHUIRCVGyM1G1unVSEtLK7Gf4wW/K1btPweryjbF7udx+kOM7ORRorGWZ6wwEBGRbMj7bRDSMGEgIiJZKM7jnZ89X8446ZGIiIgMYoWBiIhkoThLI589X86YMBARkSyY6kmPciX3+yciIqIiYIWBiIhkgUMS0jBhICIiWSjO0xqfPV/OOCRBREREBrHCQEREssAhCWmYMBARkSxwlYQ0TBiIiEgWWGGQRu4JExERERUBKwxERCQLXCUhDRMGIiKSBb58ShoOSRAREZFBrDAQEZEsKKGAUsLAgpRzXwVMGIiISBY4JCENhySIiIjIIFYYiIhIFhT//UfK+XLGhIGIiGSBQxLScEiCiIiIDGKFgYiIZEEhcZUEhySIiIhkgEMS0jBhICIiWWDCIA3nMBAREZFBrDAQEZEscFmlNEwYiIhIFpSK/E3K+XLGIQkiIiIyiBUGIiKSBQ5JSMOEgYiIZIGrJKThkAQREREZxAoDERHJggLShhVkXmBgwkBERPLAVRLScEiCiIiIDGKFQeZyc/Mwf81v+HH3Udz/5yEcq6ng16M1xg/1geKpGT4Xr2kxe8WviDtxGU9y8+Du5oRv5w1DTSd7vf4EQcDACeGI+fM81n4xHD06vlbat0Qy06Z5HYwe5IWmDVxQvZoa/pNWYeeBU+LxFZ+/j4G93tQ7Z2/cObw75mvx88ShPvBu1wiN69dETs4T1Pq/KXrt7dTWWDU7AI3q1oC9uhL+fpCOnQdOYfbX2/EwI1NsZ16xAqYM747+3V+HQxUbJP+tQ9ia37Bx+58ldPdkDK6SkKZME4bY2FjMnz8f8fHxuHv3LrZt2wZfX9+yDEl2lm3Yi3XbDmLpjPfhXtsJJ8/fwNi5m2BT2Qoj+ncEAFy7dR9vfbAYA3t7Ysrw7rCxtsSFJC0szCsW6u+bH/brJRpEJa2SlQXOXLyN73+Nw/fzRz63zd7DZzFq1vfi56zsJ3rHK1Y0Q+TeE/jrdBIGveVZ6Py8vDz8duAU5q6Mwj8PHsLNuRrmT+kPO5U1RsyIENutDR2GavY2GD1nI67evA+nqmoo+f9DucFVEtKUacKQkZGBpk2bYtiwYejbt29ZhiJbR08nwad9E3Rt2wgA4FK9CrZFH8eJc9fFNvO+2YEubTwQHNRH3FerZrVCfZ25eAvh/4nBnrWT0aTXZyUfPBGAvYfPYe/hc//aJiv7Ce798/CFx79YtRMAMKBX6+ceT3v4GN/9dFD8fFP7AN/++AfGDPIS93XxbIi2LeqimW8IUnWP8tvdTSnyfVDJU0DaxEWZ5wtlmzB0794d3bt3L8sQZO/1Jm74/pfDuHLjHuq4OODspds4cvIqZo71BZD/N6u9h88iyL8L3hv3NU5fvAWX6lUwZnBXveGGR5nZ+OjzdQid9C4cqqjK6G6Inq9dy3q4uDsUqQ8f4Y+jFzEnPAoP0jKK3Z9TVTV6d26GQ8cvifu6d2iCE+dvYOxgL/Tv/gYePc7Gb3+cxrzwKGRm5ZjiNojK1Es16TErKws6nU5vI2nGDPZCn64t0NZvLmq0G4cuAWEY+V5HvOPzOgDg7wfpyHiUhaUb9qJz64bYsvhj9Oj4GoZN/xaHn/phGbz4Z7Rq4obuHThngcqXfYfP46OQDfD9eBlClv2CNi3qYuuSj6AsxpT3NXOG4PYfC3H+t7l4mJGJMXM2icdca1TFm03roGFtDQZNXo1PFv6IPv/XDF9Nfc+Ut0MSKKGAUiFhk1Bj+OKLL6BQKDBu3DhxX2ZmJkaNGoUqVaqgcuXK6NevH5KTk/XOu3HjBnr27IlKlSrBwcEBkydPxpMn+kNq+/fvR4sWLWBhYYG6desiIiKi2HH+m5cqYQgNDYVarRY3Z2fnsg7ppffLvhP4efcxrJw5GNERU7Bshj9WborB5h1HAAB5eQIAoFv7JvhwQGc0rl8TYwZ3Rde2jbAu8hAAYNcfp3Ew/hLmjOtXZvdB9CI/R8fjt9jTOHflDnYeOAW/CeFo2agW2rWsZ3Rfnyz6CZ3e/xIDJ36DWjWrYu74/w2lKhUKCIKAkTMicPzcdUQfPodPF/+MAT3fgKVF4fk+VPoUJtiK4+jRo/jmm2/w2mv6f6EaP348tm/fjq1bt+LAgQO4c+eO3vB8bm4uevbsiezsbBw+fBjr1q1DREQEgoODxTZJSUno2bMnOnfujISEBIwbNw7Dhw/H7t27ixnti71UCcP06dORlpYmbjdv3izrkF56s5b/gtGDvPB215bwqKvBu93fwEi/zli6PhoAYG9rjQpmStR3c9I7r34tR9zWPgAAHDx2Eddu/4163lOhaTcOmnbjAACBn3yLtz9eWqr3Q2TI9dv/4O8HD1H7OfNwDLn3z0Ncup6M32JPY8K8/yDwnQ5w/O8QXPLfOty9nwbdU6smLiZpoVQqoXGwNVX49JJJT0+Hv78/Vq9eDTs7O3F/Wloavv32WyxcuBD/93//h5YtW2Lt2rU4fPgw/vwzf1XNnj17cO7cOXz//fdo1qwZunfvjtmzZ2PFihXIzs4GAISHh8PNzQ0LFixAw4YNERQUhHfeeQeLFi0y+b28VAmDhYUFVCqV3kbSPM7MLlSaNVMqkCfkVxbMK1ZAs4YuuHJDv0x25cZ9cUnlmMFd8fuGqdi3boq4AcCssX2x+DP/UrgLoqLTONjCXm2N5H+kDWkW/H9jbp4/FezIqatwqqaGtZW52KaOiwNyc/Nw516qpGuRiZioxPDs0HhWVtYLLzlq1Cj07NkTXl5eevvj4+ORk5Ojt79BgwZwcXFBXFwcACAuLg5NmjSBo6Oj2MbHxwc6nQ5nz54V2zzbt4+Pj9iHKfE5DDLn3a4xFkfsQQ1He7jXdsKZxFv45offMeCpdeuj/Ltg5IwIvNmsLtq1qIeYP89jz6Ez2LZiNADAoYrquRMdazjawVVTpdTuheTJ2socbs7/qxa4aqqgcf0aSE17hAe6DEwd0QO/xiQg+R8d3GpWxczRvrh682/sizsvnlPT0Q626kqo6WQHpVKJxvVrAACSbt5HxuNsdG3jgWpVVDhx7jrSH2WhYe3qmDnGF38mXBFXQvy46ygmB3bD8uD38cWqnahia41ZY97G99vjOOmxnDDVcxieHQ7//PPPERISUqj9Dz/8gOPHj+Po0aOFjmm1Wpibm8PW1lZvv6OjI7Rardjm6WSh4HjBsX9ro9Pp8PjxY1hZWRX9Bg0o04QhPT0dly9fFj8nJSUhISEB9vb2cHFxKcPI5GPehHfwxaodmPbVFvydkg7HaioM8m2LicO6iW16dGqKsCn9sXT9Xny28CfUcXXAt/OGoXXTOmUYOVG+Zg1dEfXNWPHzvAn5c2k2Rf2JiV9shkfdGvDr2RpqGyto76ch5sgFzAuPQnbO/yaOTf+wp97Dnf7YOB0A0OuDJTh0/BIeZ+UgwLcN5o3vC/OKFXA7ORVR+xOwKCJaPCfjcTbeHrUcX05+FzHrp+BBWga27T2OuSujSvoroFJ28+ZNvQq3hYXFc9uMHTsW0dHRsLS0LM3wSoxCEP5bey4D+/fvR+fOnQvtDwgIKNIsT51OB7VajZvJDzg8Qa8sR88xZR0CUYkRcrORdXo10tLSSuzneMHvin0JN1DZpvjXSH+oQ5dmLkWKNTIyEm+//TbMzMzEfbm5uVAoFFAqldi9eze8vLzw4MEDvSqDq6srxo0bh/HjxyM4OBi//vorEhISxONJSUmoXbs2jh8/jubNm6NDhw5o0aIFFi9eLLZZu3Ytxo0bh7S0tGLf6/OUaYWhU6dOKMN8hYiIZKQ0H9zUpUsXnD59Wm/f0KFD0aBBA0ydOhXOzs6oWLEi9u3bh3798qtiiYmJuHHjBjw985826unpiblz5+LevXtwcHAAAERHR0OlUsHDw0Nss3PnTr3rREdHi32YEucwEBERmZiNjQ0aN26st8/a2hpVqlQR9wcGBmLChAmwt7eHSqXC6NGj4enpiTffzB8e8/b2hoeHBwYNGoSwsDBotVp89tlnGDVqlDgM8uGHH2L58uWYMmUKhg0bhpiYGGzZsgU7duww+T0xYSAiInkoZ8+GXrRoEZRKJfr164esrCz4+Pjg66//91I0MzMzREVF4aOPPoKnpyesra0REBCAWbNmiW3c3NywY8cOjB8/HkuWLEHNmjWxZs0a+Pj4mDZYlPEcBqk4h4HkgHMY6FVWmnMYfj95U/Ichs5NnUs01vKMFQYiIpIFvq1SmpfqwU1ERERUNlhhICIiWShnUxheOkwYiIhIHpgxSMIhCSIiIjKIFQYiIpIFU71LQq6YMBARkSxwlYQ0HJIgIiIig1hhICIiWeCcR2mYMBARkTwwY5CEQxJERERkECsMREQkC1wlIQ0TBiIikgWukpCGCQMREckCpzBIwzkMREREZBArDEREJA8sMUjChIGIiGSBkx6l4ZAEERERGcQKAxERyQJXSUjDhIGIiGSBUxik4ZAEERERGcQKAxERyQNLDJIwYSAiIlngKglpOCRBREREBrHCQEREssBVEtIwYSAiIlngFAZpmDAQEZE8MGOQhHMYiIiIyCBWGIiISBa4SkIaJgxERCQPEic9yjxf4JAEERERGcYKAxERyQLnPErDhIGIiOSBGYMkHJIgIiIig1hhICIiWeAqCWmYMBARkSzw0dDScEiCiIiIDGKFgYiIZIFzHqVhwkBERPLAjEESDkkQEZEsKEzwjzFCQ0Px+uuvw8bGBg4ODvD19UViYqJem8zMTIwaNQpVqlRB5cqV0a9fPyQnJ+u1uXHjBnr27IlKlSrBwcEBkydPxpMnT/Ta7N+/Hy1atICFhQXq1q2LiIiIYn1H/4YJAxERUQk4cOAARo0ahT///BPR0dHIycmBt7c3MjIyxDbjx4/H9u3bsXXrVhw4cAB37txB3759xeO5ubno2bMnsrOzcfjwYaxbtw4REREIDg4W2yQlJaFnz57o3LkzEhISMG7cOAwfPhy7d+826f0oBEEQTNpjKdLpdFCr1biZ/AAqlaqswyEqEY6eY8o6BKISI+RmI+v0aqSlpZXYz/GC3xVnku7BRsI1Hup0aOzmUOxY79+/DwcHBxw4cAAdOnRAWloaqlWrhk2bNuGdd94BAFy4cAENGzZEXFwc3nzzTfz222/o1asX7ty5A0dHRwBAeHg4pk6divv378Pc3BxTp07Fjh07cObMGfFafn5+SE1Nxa5du4p9v89ihYGIiGRBYYINyE9Ant6ysrKKdP20tDQAgL29PQAgPj4eOTk58PLyEts0aNAALi4uiIuLAwDExcWhSZMmYrIAAD4+PtDpdDh79qzY5uk+CtoU9GEqTBiIiIiM4OzsDLVaLW6hoaEGz8nLy8O4cePQtm1bNG7cGACg1Wphbm4OW1tbvbaOjo7QarVim6eThYLjBcf+rY1Op8Pjx4+LdY/Pw1USREQkC6Z6cNPNmzf1hiQsLCwMnjtq1CicOXMGBw8eLH4AZYwVBiIikgnTDEqoVCq9zVDCEBQUhKioKPz++++oWbOmuN/JyQnZ2dlITU3Va5+cnAwnJyexzbOrJgo+G2qjUqlgZWVl+GspIiYMREREJUAQBAQFBWHbtm2IiYmBm5ub3vGWLVuiYsWK2Ldvn7gvMTERN27cgKenJwDA09MTp0+fxr1798Q20dHRUKlU8PDwENs83UdBm4I+TIVDEkREJAul/S6JUaNGYdOmTfjll19gY2MjzjlQq9WwsrKCWq1GYGAgJkyYAHt7e6hUKowePRqenp548803AQDe3t7w8PDAoEGDEBYWBq1Wi88++wyjRo0SKxsffvghli9fjilTpmDYsGGIiYnBli1bsGPHjuLf7HMwYSAiIlko7Qc9rly5EgDQqVMnvf1r167FkCFDAACLFi2CUqlEv379kJWVBR8fH3z99ddiWzMzM0RFReGjjz6Cp6cnrK2tERAQgFmzZolt3NzcsGPHDowfPx5LlixBzZo1sWbNGvj4+BTnNl+Iz2EgKuf4HAZ6lZXmcxguXL8v+TkMDVyrlWis5RkrDEREJAt8vbU0TBiIiEgWivM+iGfPlzMmDEREJA98W6UkXFZJREREBrHCQEREssACgzRMGIiISBY46VEaDkkQERGRQawwEBGRLHCVhDRMGIiISB44iUESDkkQERGRQawwEBGRLLDAIA0TBiIikgWukpCGQxJERERkECsMREQkE9JWSch9UIIJAxERyQKHJKThkAQREREZxISBiIiIDOKQBBERyQKHJKRhwkBERLLAR0NLwyEJIiIiMogVBiIikgUOSUjDhIGIiGSBj4aWhkMSREREZBArDEREJA8sMUjChIGIiGSBqySk4ZAEERERGcQKAxERyQJXSUjDhIGIiGSBUxikYcJARETywIxBEs5hICIiIoNYYSAiIlngKglpmDAQEZEscNKjNC91wiAIAgDg4UNdGUdCVHKE3OyyDoGoxBT8+S74eV6SdDppvyuknv+ye6kThocPHwIAPOq6lnEkREQkxcOHD6FWq0ukb3Nzczg5OaGem7PkvpycnGBubm6CqF4+CqE00roSkpeXhzt37sDGxgYKudeKSolOp4OzszNu3rwJlUpV1uEQmRT/fJc+QRDw8OFDaDQaKJUlNw8/MzMT2dnSq3Xm5uawtLQ0QUQvn5e6wqBUKlGzZs2yDkOWVCoVf6DSK4t/vktXSVUWnmZpaSnbX/SmwmWVREREZBATBiIiIjKICQMZxcLCAp9//jksLCzKOhQik+Ofb6IXe6knPRIREVHpYIWBiIiIDGLCQERERAYxYSAiIiKDmDAQERGRQUwYqMhWrFiBWrVqwdLSEq1bt8Zff/1V1iERmURsbCx69+4NjUYDhUKByMjIsg6JqNxhwkBFsnnzZkyYMAGff/45jh8/jqZNm8LHxwf37t0r69CIJMvIyEDTpk2xYsWKsg6FqNziskoqktatW+P111/H8uXLAeS/x8PZ2RmjR4/GtGnTyjg6ItNRKBTYtm0bfH19yzoUonKFFQYyKDs7G/Hx8fDy8hL3KZVKeHl5IS4urgwjIyKi0sKEgQz6+++/kZubC0dHR739jo6O0Gq1ZRQVERGVJiYMREREZBATBjKoatWqMDMzQ3Jyst7+5ORkODk5lVFURERUmpgwkEHm5uZo2bIl9u3bJ+7Ly8vDvn374OnpWYaRERFRaalQ1gHQy2HChAkICAhAq1at8MYbb2Dx4sXIyMjA0KFDyzo0IsnS09Nx+fJl8XNSUhISEhJgb28PFxeXMoyMqPzgskoqsuXLl2P+/PnQarVo1qwZli5ditatW5d1WESS7d+/H507dy60PyAgABEREaUfEFE5xISBiIiIDOIcBiIiIjKICQMREREZxISBiIiIDGLCQERERAYxYSAiIiKDmDAQERGRQUwYiIiIyCAmDEQSDRkyBL6+vuLnTp06Ydy4caUex/79+6FQKJCamvrCNgqFApGRkUXuMyQkBM2aNZMU17Vr16BQKJCQkCCpHyIqW0wY6JU0ZMgQKBQKKBQKmJubo27dupg1axaePHlS4tf++eefMXv27CK1LcoveSKi8oDvkqBXVrdu3bB27VpkZWVh586dGDVqFCpWrIjp06cXapudnQ1zc3OTXNfe3t4k/RARlSesMNAry8LCAk5OTnB1dcVHH30ELy8v/PrrrwD+N4wwd+5caDQauLu7AwBu3ryJ/v37w9bWFvb29ujTpw+uXbsm9pmbm4sJEybA1tYWVapUwZQpU/Ds09WfHZLIysrC1KlT4ezsDAsLC9StWxfffvstrl27Jr6/wM7ODgqFAkOGDAGQ/zbQ0NBQuLm5wcrKCk2bNsWPP/6od52dO3eifv36sLKyQufOnfXiLKqpU6eifv36qFSpEmrXro0ZM2YgJyenULtvvvkGzs7OqFSpEvr374+0tDS942vWrEHDhg1haWmJBg0a4OuvvzY6FiIq35gwkGxYWVkhOztb/Lxv3z4kJiYiOjoaUVFRyMnJgY+PD2xsbPDHH3/g0KFDqFy5Mrp16yaet2DBAkREROC7777DwYMHkZKSgm3btv3rdQcPHoz//Oc/WLp0Kc6fP49vvvkGlStXhrOzM3766ScAQGJiIu7evYslS5YAAEJDQ7F+/XqEh4fj7NmzGD9+PN5//30cOHAAQH5i07dvX/Tu3RsJCQkYPnw4pk2bZvR3YmNjg4iICJw7dw5LlizB6tWrsWjRIr02ly9fxpYtW7B9+3bs2rULJ06cwMcffywe37hxI4KDgzF37lycP38e8+bNw4wZM7Bu3Tqj4yGickwgegUFBAQIffr0EQRBEPLy8oTo6GjBwsJCmDRpknjc0dFRyMrKEs/ZsGGD4O7uLuTl5Yn7srKyBCsrK2H37t2CIAhC9erVhbCwMPF4Tk6OULNmTfFagiAIHTt2FMaOHSsIgiAkJiYKAITo6Ojnxvn7778LAIQHDx6I+zIzM4VKlSoJhw8f1msbGBgoDBgwQBAEQZg+fbrg4eGhd3zq1KmF+noWAGHbtm0vPD5//nyhZcuW4ufPP/9cMDMzE27duiXu++233wSlUincvXtXEARBqFOnjrBp0ya9fmbPni14enoKgiAISUlJAgDhxIkTL7wuEZV/nMNAr6yoqChUrlwZOTk5yMvLw8CBAxESEiIeb9Kkid68hZMnT+Ly5cuwsbHR6yczMxNXrlxBWloa7t69q/dK7woVKqBVq1aFhiUKJCQkwMzMDB07dixy3JcvX8ajR4/QtWtXvf3Z2dlo3rw5AOD8+fOFXi3u6elZ5GsU2Lx5M5YuXYorV64gPT0dT548gUql0mvj4uKCGjVq6F0nLy8PiYmJsLGxwZUrVxAYGIgRI0aIbZ48eQK1Wm10PERUfjFhoFdW586dsXLlSpibm0Oj0aBCBf0/7tbW1nqf09PT0bJlS2zcuLFQX9WqVStWDFZWVkafk56eDgDYsWOH3i9qIH9ehqnExcXB398fM2fOhI+PD9RqNX744QcsWLDA6FhXr15dKIExMzMzWaxEVPaYMNAry9raGnXr1i1y+xYtWmDz5s1wcHAo9LfsAtWrV8eRI0fQoUMHAPl/k46Pj0eLFi2e275JkybIy8vDgQMH4OXlVeh4QYUjNzdX3Ofh4QELCwvcuHHjhZWJhg0bihM4C/z555+Gb/Iphw8fhqurKz799FNx3/Xr1wu1u3HjBu7cuQONRiNeR6lUwt3dHY6OjtBoNLh69Sr8/f2Nuj4RvVw46ZHov/z9/VG1alX06dMHf/zxB5KSkrB//36MGTMGt27dAgCMHTsWX3zxBSIjI3HhwgV8/PHH//oMhVq1aiEgIADDhg1DZGSk2OeWLVsAAK6urlAoFIiKisL9+/eRnp4OGxsbTJo0CePHj8e6detw5coVHD9+HMuWLRMnEn744Ye4dOkSJk+ejMTERGzatAkRERFG3W+9evVw48YN/PDDD7hy5QqWLl363AmclpaWCAgIwMmTJ/HHH39gzJgx6N+/P5ycnAAAM2fORGhoKJYuXYqLFy/i9OnTWLt2LRYuXGhUPERUvjFhIPqvSpUqITY2Fi4uLujbty8aNmyIwMBAZGZmihWHiRMnYtCgQQgICICnpydsbGzw9ttv/2u/K1euxDvvvIOPP/4YDRo0wIgRI5CRkQEAqFGjBmbOnIlp06bB0dERQUFBAIDZs2djxowZCA0NRcOGDdGtWzfs2LEDbm5uAPLnFfz000+IjIxE06ZNER4ejnnz5hl1v2+99RbGjx+PoKAgNGvWDIcPH8aMGTMKtatbty769u2LHj16wNvbG6+99pressnhw4djzZo1WLt2LZo0aYKOHTsiIiJCjJWIXg0K4UWztYiIiIj+ixUGIiIiMogJAxERERnEhIGIiIgMYsJAREREBjFhICIiIoOYMBAREZFBTBiIiIjIICYMREREZBATBiIiIjKICQMREREZxISBiIiIDGLCQERERAb9P6p3RW6rgtvcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator()\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=64)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=64)\n",
    "\n",
    "# Callbacks for training\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_model_mobilenetv1_l2_RK_Nov23.keras', save_best_only=True, monitor='val_loss'),\n",
    "    EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('final_model_mobilenetv1_l2_RK_Nov23.keras')\n",
    "\n",
    "# Load test data\n",
    "test_image_folder = 'Dataset_Model/Final_dataset/17k_test_images'  # Replace with your test spectrogram images path\n",
    "test_txt_folder = 'Dataset_Model/Final_dataset/17k_test_labels'  # Replace with your test labels path\n",
    "X_test, y_test = load_data(test_image_folder, test_txt_folder, (128, 128))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0, 1])\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
