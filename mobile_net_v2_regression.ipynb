{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, BatchNormalization, ReLU\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2  # Import L2 regularizer\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess spectrograms\n",
    "def preprocess_spectrogram(spectrogram, target_size):\n",
    "    # Normalize\n",
    "    spectrogram = spectrogram / np.max(spectrogram)\n",
    "    # Resize to match MobileNet input\n",
    "    spectrogram = tf.image.resize(spectrogram, target_size)\n",
    "    # Convert to 3 channels (stack the same data for all channels)\n",
    "    spectrogram = tf.image.grayscale_to_rgb(spectrogram)\n",
    "    return spectrogram.numpy()\n",
    "\n",
    "# Data augmentation for spectrograms\n",
    "def augment_spectrogram(spectrogram):\n",
    "    # Time shifting\n",
    "    shift = random.randint(-10, 10)\n",
    "    spectrogram = np.roll(spectrogram, shift, axis=1)\n",
    "\n",
    "    # Frequency masking\n",
    "    freq_mask = random.randint(0, 10)\n",
    "    spectrogram[:, freq_mask:freq_mask + 10, :] = 0\n",
    "\n",
    "    # Time masking\n",
    "    time_mask = random.randint(0, 10)\n",
    "    spectrogram[time_mask:time_mask + 10, :, :] = 0\n",
    "\n",
    "    return spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 1e-4  # Start with a higher learning rate\n",
    "decay_steps = 1000            # Number of steps before applying decay\n",
    "decay_rate = 0.9              # Rate of decay\n",
    "learning_rate_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=True  # Decay happens in discrete intervals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_regression_model(input_shape, num_outputs):\n",
    "    '''\n",
    "    # Define Exponential Decay for the learning rate\n",
    "    initial_learning_rate = 1e-4\n",
    "    decay_steps = 1000\n",
    "    decay_rate = 0.9\n",
    "    learning_rate_schedule = ExponentialDecay(\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        staircase=True\n",
    "    )\n",
    "'''\n",
    "    # Load MobileNetV2 with pre-trained weights from ImageNet\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Fine-tune MobileNetV2\n",
    "    base_model.trainable = True  # Allow all layers to be trainable initially\n",
    "\n",
    "    # Freeze all layers except the last 3\n",
    "    for layer in base_model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers with L2 regularization\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.009)),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.009)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_outputs, kernel_regularizer=l2(0.009))  # Output layer for regression\n",
    "    ])\n",
    "\n",
    "    # Compile the model with the learning rate schedule\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule),\n",
    "        loss='mean_squared_error',  # Loss function for regression\n",
    "        metrics=['mean_absolute_error']  # Metrics for regression\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_128            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,474,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_128            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m1,474,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,996,101</span> (15.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,996,101\u001b[0m (15.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,470,341</span> (9.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,470,341\u001b[0m (9.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,525,760</span> (5.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,525,760\u001b[0m (5.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input shape for spectrograms\n",
    "input_shape = (128, 128, 3)\n",
    "num_outputs = 5\n",
    "\n",
    "# Create the model for regression\n",
    "model = create_regression_model(input_shape, num_outputs)\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(\n",
    "    #optimizer=tf.keras.optimizers.Adam(learning_rate=ExponentialDecay(\n",
    "     #   initial_learning_rate=1e-4,\n",
    "      #  decay_steps=1000,\n",
    "       # decay_rate=0.9,\n",
    "        #staircase=True\n",
    "    #)),\n",
    "#    loss='mean_squared_error',  # Loss function for regression\n",
    "#    metrics=['mean_absolute_error']  # Metrics for regression\n",
    "#)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport time\\nimport numpy as np\\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\\n\\ndef load_data(image_folder, txt_folder, target_size):\\n    start_time = time.time()\\n    images = []\\n    labels = []\\n\\n    for txt_file in os.listdir(txt_folder):\\n        if txt_file.endswith(\\'.txt\\'):\\n            # Read and parse the label as a list of floats\\n            with open(os.path.join(txt_folder, txt_file), \\'r\\') as file:\\n                label = list(map(float, file.read().strip().split()))  # Convert space-separated floats to a list\\n\\n            # Load the corresponding image\\n            image_name = os.path.splitext(txt_file)[0] + \\'.jpg\\'  # Assuming spectrograms are in .jpg format\\n            image_path = os.path.join(image_folder, image_name)\\n            if os.path.exists(image_path):\\n                image = load_img(image_path, target_size=target_size)\\n                image = img_to_array(image)\\n                images.append(image)\\n                labels.append(label)\\n\\n    end_time = time.time()\\n    elapsed_time = end_time - start_time\\n    print(f\"Time taken to load the dataset: {elapsed_time:.2f} seconds\")\\n\\n    return np.array(images), np.array(labels)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_data(image_folder, txt_folder, target_size):\n",
    "    start_time = time.time()\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for txt_file in os.listdir(txt_folder):\n",
    "        if txt_file.endswith('.txt'):\n",
    "            # Read and parse the label as a list of floats\n",
    "            with open(os.path.join(txt_folder, txt_file), 'r') as file:\n",
    "                label = list(map(float, file.read().strip().split()))  # Convert space-separated floats to a list\n",
    "\n",
    "            # Load the corresponding image\n",
    "            image_name = os.path.splitext(txt_file)[0] + '.jpg'  # Assuming spectrograms are in .jpg format\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            if os.path.exists(image_path):\n",
    "                image = load_img(image_path, target_size=target_size)\n",
    "                image = img_to_array(image)\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken to load the dataset: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return np.array(images), np.array(labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport time\\nimport numpy as np\\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\\nfrom PIL import UnidentifiedImageError\\n\\ndef load_data(image_folder, txt_folder, target_size):\\n    start_time = time.time()\\n    images = []\\n    labels = []\\n    processed_files = 0  # Counter for processed files\\n\\n    for txt_file in os.listdir(txt_folder):\\n        if txt_file.endswith(\\'.txt\\'):\\n            # Read and parse the label as a list of floats\\n            with open(os.path.join(txt_folder, txt_file), \\'r\\') as file:\\n                label = list(map(float, file.read().strip().split()))  # Convert space-separated floats to a list\\n\\n            # Load the corresponding image\\n            image_name = os.path.splitext(txt_file)[0] + \\'.jpg\\'  # Assuming spectrograms are in .jpg format\\n            image_path = os.path.join(image_folder, image_name)\\n\\n            if os.path.exists(image_path):\\n                try:\\n                    image = load_img(image_path, target_size=target_size)\\n                    image = img_to_array(image)\\n                    images.append(image)\\n                    labels.append(label)\\n                    processed_files += 1\\n                except UnidentifiedImageError:\\n                    print(f\"Warning: {image_path} could not be identified as an image and was skipped.\")\\n                except Exception as e:\\n                    print(f\"Warning: An error occurred with {image_path} - {e}\")\\n            else:\\n                print(f\"Warning: Image {image_path} does not exist.\")\\n    \\n    end_time = time.time()\\n    elapsed_time = end_time - start_time\\n    print(f\"Total processed files: {processed_files}\")\\n    print(f\"Time taken to load the dataset: {elapsed_time:.2f} seconds\")\\n    return np.array(images), np.array(labels)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "def load_data(image_folder, txt_folder, target_size):\n",
    "    start_time = time.time()\n",
    "    images = []\n",
    "    labels = []\n",
    "    processed_files = 0  # Counter for processed files\n",
    "\n",
    "    for txt_file in os.listdir(txt_folder):\n",
    "        if txt_file.endswith('.txt'):\n",
    "            # Read and parse the label as a list of floats\n",
    "            with open(os.path.join(txt_folder, txt_file), 'r') as file:\n",
    "                label = list(map(float, file.read().strip().split()))  # Convert space-separated floats to a list\n",
    "\n",
    "            # Load the corresponding image\n",
    "            image_name = os.path.splitext(txt_file)[0] + '.jpg'  # Assuming spectrograms are in .jpg format\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "            if os.path.exists(image_path):\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=target_size)\n",
    "                    image = img_to_array(image)\n",
    "                    images.append(image)\n",
    "                    labels.append(label)\n",
    "                    processed_files += 1\n",
    "                except UnidentifiedImageError:\n",
    "                    print(f\"Warning: {image_path} could not be identified as an image and was skipped.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: An error occurred with {image_path} - {e}\")\n",
    "            else:\n",
    "                print(f\"Warning: Image {image_path} does not exist.\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total processed files: {processed_files}\")\n",
    "    print(f\"Time taken to load the dataset: {elapsed_time:.2f} seconds\")\n",
    "    return np.array(images), np.array(labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport time\\nimport numpy as np\\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\\nfrom PIL import UnidentifiedImageError\\n\\ndef load_data(image_folder, txt_folder, target_size, fraction=1.0):\\n    start_time = time.time()\\n    images = []\\n    labels = []\\n    processed_files = 0  # Counter for processed files\\n\\n    # List all text files in the label folder\\n    txt_files = [f for f in os.listdir(txt_folder) if f.endswith(\\'.txt\\')]\\n\\n    # Randomly select a fraction of the text files\\n    sample_size = int(fraction * len(txt_files))\\n    np.random.seed(42)  # For reproducibility\\n    selected_files = np.random.choice(txt_files, size=sample_size, replace=False)\\n\\n    for txt_file in selected_files:\\n        # Read and parse the label as a list of floats\\n        with open(os.path.join(txt_folder, txt_file), \\'r\\') as file:\\n            label_values = file.read().strip().split()\\n            # Depending on your requirements, select the desired label value\\n            desired_index = 1  # Adjust this index as needed\\n            label = float(label_values[desired_index])\\n\\n        # Load the corresponding image\\n        image_name = os.path.splitext(txt_file)[0] + \\'.jpg\\'  # Assuming spectrograms are in .jpg format\\n        image_path = os.path.join(image_folder, image_name)\\n\\n        if os.path.exists(image_path):\\n            try:\\n                image = load_img(image_path, target_size=target_size)\\n                image = img_to_array(image)\\n                images.append(image)\\n                labels.append(label)\\n                processed_files += 1\\n            except UnidentifiedImageError:\\n                print(f\"Warning: {image_path} could not be identified as an image and was skipped.\")\\n            except Exception as e:\\n                print(f\"Warning: An error occurred with {image_path} - {e}\")\\n        else:\\n            print(f\"Warning: Image {image_path} does not exist.\")\\n\\n    end_time = time.time()\\n    elapsed_time = end_time - start_time\\n    print(f\"Total processed files: {processed_files}\")\\n    print(f\"Time taken to load the dataset: {elapsed_time:.2f} seconds\")\\n    return np.array(images), np.array(labels)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "def load_data(image_folder, txt_folder, target_size, fraction=1.0):\n",
    "    start_time = time.time()\n",
    "    images = []\n",
    "    labels = []\n",
    "    processed_files = 0  # Counter for processed files\n",
    "\n",
    "    # List all text files in the label folder\n",
    "    txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "\n",
    "    # Randomly select a fraction of the text files\n",
    "    sample_size = int(fraction * len(txt_files))\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    selected_files = np.random.choice(txt_files, size=sample_size, replace=False)\n",
    "\n",
    "    for txt_file in selected_files:\n",
    "        # Read and parse the label as a list of floats\n",
    "        with open(os.path.join(txt_folder, txt_file), 'r') as file:\n",
    "            label_values = file.read().strip().split()\n",
    "            # Depending on your requirements, select the desired label value\n",
    "            desired_index = 1  # Adjust this index as needed\n",
    "            label = float(label_values[desired_index])\n",
    "\n",
    "        # Load the corresponding image\n",
    "        image_name = os.path.splitext(txt_file)[0] + '.jpg'  # Assuming spectrograms are in .jpg format\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            try:\n",
    "                image = load_img(image_path, target_size=target_size)\n",
    "                image = img_to_array(image)\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                processed_files += 1\n",
    "            except UnidentifiedImageError:\n",
    "                print(f\"Warning: {image_path} could not be identified as an image and was skipped.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: An error occurred with {image_path} - {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Image {image_path} does not exist.\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total processed files: {processed_files}\")\n",
    "    print(f\"Time taken to load the dataset: {elapsed_time:.2f} seconds\")\n",
    "    return np.array(images), np.array(labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Paths to dataset\\nimage_folder = '/Users/goutham/Updated/reg_48k_train_images'  # Replace with your spectrogram images path\\ntxt_folder = '/Users/goutham/Updated/reg_48k_train_labels'    # Replace with your labels path\\n\\n# Load only 50% of the data\\nX, y = load_data(image_folder, txt_folder, (128, 128), fraction=0.5)\\n\\n# Proceed with train-test split for regression\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_val, y_train, y_val = train_test_split(\\n    X, y, test_size=0.2, random_state=42\\n)\\n\\n# Create data generators\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\\ntrain_datagen = ImageDataGenerator(\\n    rescale=1./255  # Normalize image pixel values to [0, 1]\\n)\\nval_datagen = ImageDataGenerator(\\n    rescale=1./255  # Normalize image pixel values to [0, 1]\\n)\\n\\n# Generators for training and validation\\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=64)\\nval_generator = val_datagen.flow(X_val, y_val, batch_size=64)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Paths to dataset\n",
    "image_folder = '/Users/goutham/Updated/reg_48k_train_images'  # Replace with your spectrogram images path\n",
    "txt_folder = '/Users/goutham/Updated/reg_48k_train_labels'    # Replace with your labels path\n",
    "\n",
    "# Load only 50% of the data\n",
    "X, y = load_data(image_folder, txt_folder, (128, 128), fraction=0.5)\n",
    "\n",
    "# Proceed with train-test split for regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create data generators\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255  # Normalize image pixel values to [0, 1]\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255  # Normalize image pixel values to [0, 1]\n",
    ")\n",
    "\n",
    "# Generators for training and validation\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=64)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=64)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def load_data(image_folder, txt_folder, target_size):\\n    start_time = time.time()\\n    images = []\\n    labels = []\\n    \\n    txt_files = [f for f in os.listdir(txt_folder) if f.endswith(\\'.txt\\')]\\n\\n    with ThreadPoolExecutor() as executor:\\n        futures = [executor.submit(load_single_data, txt_file, image_folder, txt_folder, target_size) for txt_file in txt_files]\\n        for future in futures:\\n            result = future.result()\\n            if result is not None:\\n                image, label = result\\n                images.append(image)\\n                labels.append(label)\\n\\n    end_time = time.time()\\n    elapsed_time = end_time - start_time\\n    print(f\"Time taken to load the dataset: {elapsed_time:.2f} seconds\")\\n\\n    return np.array(images), np.array(labels)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "def load_data(image_folder, txt_folder, target_size, fraction=1.0):\n",
    "    start_time = time.time()\n",
    "    images = []\n",
    "    labels = []\n",
    "    processed_files = 0  # Counter for processed files\n",
    "\n",
    "    # List all text files in the label folder\n",
    "    txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "\n",
    "    # Randomly select a fraction of the text files\n",
    "    sample_size = int(fraction * len(txt_files))\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    selected_files = np.random.choice(txt_files, size=sample_size, replace=False)\n",
    "\n",
    "    for txt_file in selected_files:\n",
    "        # Read and parse the label as a list of floats\n",
    "        with open(os.path.join(txt_folder, txt_file), 'r') as file:\n",
    "            label_values = file.read().strip().split()\n",
    "            # Convert all label values to floats\n",
    "            label = [float(value) for value in label_values]\n",
    "\n",
    "        # Load the corresponding image\n",
    "        image_name = os.path.splitext(txt_file)[0] + '.jpg'  # Assuming spectrograms are in .jpg format\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            try:\n",
    "                image = load_img(image_path, target_size=target_size)\n",
    "                image = img_to_array(image)\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                processed_files += 1\n",
    "            except UnidentifiedImageError:\n",
    "                print(f\"Warning: {image_path} could not be identified as an image and was skipped.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: An error occurred with {image_path} - {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Image {image_path} does not exist.\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total processed files: {processed_files}\")\n",
    "    print(f\"Time taken to load the dataset: {elapsed_time:.2f} seconds\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "'''def load_data(image_folder, txt_folder, target_size):\n",
    "    start_time = time.time()\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(load_single_data, txt_file, image_folder, txt_folder, target_size) for txt_file in txt_files]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                image, label = result\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken to load the dataset: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return np.array(images), np.array(labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed files: 24000\n",
      "Time taken to load the dataset: 34.94 seconds\n"
     ]
    }
   ],
   "source": [
    "# Paths to dataset\n",
    "image_folder = '/Users/goutham/Updated/reg_48k_train_images'  # Replace with your spectrogram images path\n",
    "txt_folder = '/Users/goutham/Updated/reg_48k_train_labels'    # Replace with your labels path\n",
    "\n",
    "# Load only 50% of the data\n",
    "X, y = load_data(image_folder, txt_folder, (128, 128), fraction=0.5)\n",
    "\n",
    "# Proceed with train-test split for regression\n",
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into 70% training and 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "# Further split training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create data generators\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255  # Normalize image pixel values to [0, 1]\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Generators for training and validation\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=64)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=64)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13440, 128, 128, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13440, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for training\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_model_mobilenetv2_l2_regression.keras', save_best_only=True, monitor='val_loss'),\n",
    "    EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True),  # Increased patience slightly for regression\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)  # Increased patience for LR reduction\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goutham/miniconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 301ms/step - loss: 4.8177 - mean_absolute_error: 0.5091 - val_loss: 3.8303 - val_mean_absolute_error: 0.1791 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 288ms/step - loss: 3.6585 - mean_absolute_error: 0.2129 - val_loss: 3.0259 - val_mean_absolute_error: 0.1573 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 292ms/step - loss: 2.8467 - mean_absolute_error: 0.1812 - val_loss: 2.2708 - val_mean_absolute_error: 0.1518 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 293ms/step - loss: 2.1096 - mean_absolute_error: 0.1618 - val_loss: 1.6247 - val_mean_absolute_error: 0.1205 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 300ms/step - loss: 1.5037 - mean_absolute_error: 0.1445 - val_loss: 1.1411 - val_mean_absolute_error: 0.1137 - learning_rate: 9.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 339ms/step - loss: 1.0570 - mean_absolute_error: 0.1313 - val_loss: 0.8223 - val_mean_absolute_error: 0.1502 - learning_rate: 9.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 345ms/step - loss: 0.7393 - mean_absolute_error: 0.1187 - val_loss: 0.5541 - val_mean_absolute_error: 0.1026 - learning_rate: 9.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 331ms/step - loss: 0.5098 - mean_absolute_error: 0.1121 - val_loss: 0.3774 - val_mean_absolute_error: 0.0948 - learning_rate: 9.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 317ms/step - loss: 0.3481 - mean_absolute_error: 0.1063 - val_loss: 0.2575 - val_mean_absolute_error: 0.0900 - learning_rate: 9.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 318ms/step - loss: 0.2391 - mean_absolute_error: 0.1024 - val_loss: 0.1765 - val_mean_absolute_error: 0.0729 - learning_rate: 8.1000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 331ms/step - loss: 0.1695 - mean_absolute_error: 0.0964 - val_loss: 0.1318 - val_mean_absolute_error: 0.0857 - learning_rate: 8.1000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 326ms/step - loss: 0.1243 - mean_absolute_error: 0.0934 - val_loss: 0.0955 - val_mean_absolute_error: 0.0753 - learning_rate: 8.1000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 337ms/step - loss: 0.0940 - mean_absolute_error: 0.0911 - val_loss: 0.0706 - val_mean_absolute_error: 0.0598 - learning_rate: 8.1000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 333ms/step - loss: 0.0727 - mean_absolute_error: 0.0875 - val_loss: 0.0576 - val_mean_absolute_error: 0.0702 - learning_rate: 8.1000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 319ms/step - loss: 0.0583 - mean_absolute_error: 0.0841 - val_loss: 0.0447 - val_mean_absolute_error: 0.0558 - learning_rate: 7.2900e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 324ms/step - loss: 0.0477 - mean_absolute_error: 0.0787 - val_loss: 0.0386 - val_mean_absolute_error: 0.0611 - learning_rate: 7.2900e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 327ms/step - loss: 0.0404 - mean_absolute_error: 0.0760 - val_loss: 0.0320 - val_mean_absolute_error: 0.0556 - learning_rate: 7.2900e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 345ms/step - loss: 0.0348 - mean_absolute_error: 0.0742 - val_loss: 0.0278 - val_mean_absolute_error: 0.0544 - learning_rate: 7.2900e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 353ms/step - loss: 0.0303 - mean_absolute_error: 0.0730 - val_loss: 0.0246 - val_mean_absolute_error: 0.0540 - learning_rate: 7.2900e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 344ms/step - loss: 0.0268 - mean_absolute_error: 0.0706 - val_loss: 0.0219 - val_mean_absolute_error: 0.0555 - learning_rate: 6.5610e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 327ms/step - loss: 0.0235 - mean_absolute_error: 0.0683 - val_loss: 0.0201 - val_mean_absolute_error: 0.0572 - learning_rate: 6.5610e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 317ms/step - loss: 0.0210 - mean_absolute_error: 0.0667 - val_loss: 0.0158 - val_mean_absolute_error: 0.0414 - learning_rate: 6.5610e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 318ms/step - loss: 0.0188 - mean_absolute_error: 0.0641 - val_loss: 0.0143 - val_mean_absolute_error: 0.0460 - learning_rate: 6.5610e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 316ms/step - loss: 0.0170 - mean_absolute_error: 0.0627 - val_loss: 0.0130 - val_mean_absolute_error: 0.0449 - learning_rate: 5.9049e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 316ms/step - loss: 0.0152 - mean_absolute_error: 0.0601 - val_loss: 0.0117 - val_mean_absolute_error: 0.0434 - learning_rate: 5.9049e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 321ms/step - loss: 0.0141 - mean_absolute_error: 0.0588 - val_loss: 0.0130 - val_mean_absolute_error: 0.0568 - learning_rate: 5.9049e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 320ms/step - loss: 0.0132 - mean_absolute_error: 0.0575 - val_loss: 0.0099 - val_mean_absolute_error: 0.0417 - learning_rate: 5.9049e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 334ms/step - loss: 0.0123 - mean_absolute_error: 0.0567 - val_loss: 0.0108 - val_mean_absolute_error: 0.0515 - learning_rate: 5.9049e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 337ms/step - loss: 0.0114 - mean_absolute_error: 0.0555 - val_loss: 0.0088 - val_mean_absolute_error: 0.0420 - learning_rate: 5.3144e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 346ms/step - loss: 0.0109 - mean_absolute_error: 0.0550 - val_loss: 0.0082 - val_mean_absolute_error: 0.0414 - learning_rate: 5.3144e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 376ms/step - loss: 0.0103 - mean_absolute_error: 0.0540 - val_loss: 0.0075 - val_mean_absolute_error: 0.0369 - learning_rate: 5.3144e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 337ms/step - loss: 0.0100 - mean_absolute_error: 0.0537 - val_loss: 0.0072 - val_mean_absolute_error: 0.0374 - learning_rate: 5.3144e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 346ms/step - loss: 0.0095 - mean_absolute_error: 0.0526 - val_loss: 0.0067 - val_mean_absolute_error: 0.0360 - learning_rate: 5.3144e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 433ms/step - loss: 0.0092 - mean_absolute_error: 0.0519 - val_loss: 0.0068 - val_mean_absolute_error: 0.0375 - learning_rate: 4.7830e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 438ms/step - loss: 0.0089 - mean_absolute_error: 0.0510 - val_loss: 0.0063 - val_mean_absolute_error: 0.0345 - learning_rate: 4.7830e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 400ms/step - loss: 0.0087 - mean_absolute_error: 0.0507 - val_loss: 0.0062 - val_mean_absolute_error: 0.0354 - learning_rate: 4.7830e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 349ms/step - loss: 0.0086 - mean_absolute_error: 0.0507 - val_loss: 0.0062 - val_mean_absolute_error: 0.0361 - learning_rate: 4.7830e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 338ms/step - loss: 0.0083 - mean_absolute_error: 0.0496 - val_loss: 0.0063 - val_mean_absolute_error: 0.0369 - learning_rate: 4.7830e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 336ms/step - loss: 0.0082 - mean_absolute_error: 0.0488 - val_loss: 0.0058 - val_mean_absolute_error: 0.0331 - learning_rate: 4.3047e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 353ms/step - loss: 0.0080 - mean_absolute_error: 0.0480 - val_loss: 0.0062 - val_mean_absolute_error: 0.0375 - learning_rate: 4.3047e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 358ms/step - loss: 0.0079 - mean_absolute_error: 0.0473 - val_loss: 0.0060 - val_mean_absolute_error: 0.0353 - learning_rate: 4.3047e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 355ms/step - loss: 0.0078 - mean_absolute_error: 0.0467 - val_loss: 0.0057 - val_mean_absolute_error: 0.0331 - learning_rate: 4.3047e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 343ms/step - loss: 0.0077 - mean_absolute_error: 0.0462 - val_loss: 0.0059 - val_mean_absolute_error: 0.0351 - learning_rate: 3.8742e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 344ms/step - loss: 0.0076 - mean_absolute_error: 0.0457 - val_loss: 0.0056 - val_mean_absolute_error: 0.0338 - learning_rate: 3.8742e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 356ms/step - loss: 0.0076 - mean_absolute_error: 0.0454 - val_loss: 0.0059 - val_mean_absolute_error: 0.0375 - learning_rate: 3.8742e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 346ms/step - loss: 0.0073 - mean_absolute_error: 0.0446 - val_loss: 0.0055 - val_mean_absolute_error: 0.0331 - learning_rate: 3.8742e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 325ms/step - loss: 0.0073 - mean_absolute_error: 0.0444 - val_loss: 0.0055 - val_mean_absolute_error: 0.0331 - learning_rate: 3.8742e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 326ms/step - loss: 0.0073 - mean_absolute_error: 0.0442 - val_loss: 0.0058 - val_mean_absolute_error: 0.0358 - learning_rate: 3.4868e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 349ms/step - loss: 0.0072 - mean_absolute_error: 0.0439 - val_loss: 0.0054 - val_mean_absolute_error: 0.0338 - learning_rate: 3.4868e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 344ms/step - loss: 0.0071 - mean_absolute_error: 0.0438 - val_loss: 0.0055 - val_mean_absolute_error: 0.0316 - learning_rate: 3.4868e-05\n",
      "Model saved to: /Users/goutham/Updated/mobilenetv2_l2_REGRESSION.keras\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Define the directory to save the model\n",
    "save_dir = '/Users/goutham/Updated'  # You can replace this with your desired directory path\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Full path to save the model\n",
    "save_path = os.path.join(save_dir, 'mobilenetv2_l2_REGRESSION.keras')\n",
    "\n",
    "# Save the trained model\n",
    "model.save(save_path)\n",
    "\n",
    "print(f\"Model saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step\n",
      "Test Mean Absolute Error (MAE): 0.0338\n",
      "Test Mean Squared Error (MSE): 0.0044\n"
     ]
    }
   ],
   "source": [
    "# Normalize the test data\n",
    "X_test = X_test / 255.0  # Since we used rescale=1./255 in the generators\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute regression metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Test Mean Squared Error (MSE): {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed files: 15999\n",
      "Time taken to load the dataset: 26.19 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_image_folder = '/Users/goutham/Updated/reg_test_images'  # Replace with your test spectrogram images path\n",
    "test_txt_folder = '/Users/goutham/Updated/reg_test_labels'  # Replace with your test labels path\n",
    "X_test, y_test = load_data(test_image_folder, test_txt_folder, (128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19200, 128, 128, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 85ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = ['mean_absolute_error', 'mape', 'r2_keras']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compute metrics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, \u001b[43mtest_predictions\u001b[49m)\n\u001b[1;32m      5\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, test_predictions)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(mae)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute metrics\n",
    "mae = mean_absolute_error(y_test, test_predictions)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.028882897693151978)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.      0.55078 0.5     0.13281 0.99609]\n",
      " [0.      0.61719 0.5     0.12891 0.99609]\n",
      " [0.      0.45703 0.5     0.13281 0.99609]\n",
      " [0.      0.39062 0.5     0.13281 0.99609]\n",
      " [0.      0.39453 0.5     0.13281 0.99609]\n",
      " [0.      0.66211 0.5     0.12891 0.99609]\n",
      " [0.      0.28125 0.5     0.12891 0.99609]\n",
      " [0.      0.52539 0.5     0.13281 0.99609]\n",
      " [0.      0.69531 0.5     0.13281 0.99609]\n",
      " [0.      0.53711 0.5     0.13281 0.99609]\n",
      " [0.      0.40234 0.5     0.12891 0.99609]\n",
      " [0.      0.4375  0.5     0.12891 0.99609]\n",
      " [0.      0.6543  0.5     0.13281 0.99609]\n",
      " [0.      0.58398 0.5     0.12891 0.99609]\n",
      " [0.      0.56055 0.5     0.13281 0.99609]\n",
      " [0.      0.30859 0.5     0.12891 0.99609]\n",
      " [0.      0.69727 0.5     0.13281 0.99609]\n",
      " [0.      0.67969 0.5     0.13281 0.99609]\n",
      " [0.      0.71094 0.5     0.13281 0.99609]\n",
      " [0.      0.375   0.5     0.12891 0.99609]\n",
      " [0.      0.59961 0.5     0.12891 0.99609]\n",
      " [0.      0.5957  0.5     0.13281 0.99609]\n",
      " [0.      0.31445 0.5     0.13281 0.99609]\n",
      " [0.      0.33789 0.5     0.13281 0.99609]\n",
      " [0.      0.69727 0.5     0.13281 0.99609]\n",
      " [0.      0.5     0.5     0.13281 0.99609]\n",
      " [0.      0.43164 0.5     0.13281 0.99609]\n",
      " [0.      0.44141 0.5     0.13281 0.99609]\n",
      " [0.      0.47266 0.5     0.13281 0.99609]\n",
      " [0.      0.41211 0.5     0.12891 0.99609]\n",
      " [0.      0.49414 0.5     0.12891 0.99609]\n",
      " [0.      0.55859 0.5     0.12891 0.99609]\n",
      " [0.      0.6582  0.5     0.13281 0.99609]\n",
      " [0.      0.43164 0.5     0.13281 0.99609]\n",
      " [0.      0.42188 0.5     0.13281 0.99609]\n",
      " [0.      0.53906 0.5     0.12891 0.99609]\n",
      " [0.      0.50977 0.5     0.13281 0.99609]\n",
      " [0.      0.57812 0.5     0.12891 0.99609]\n",
      " [0.      0.38281 0.5     0.13281 0.99609]\n",
      " [0.      0.74609 0.5     0.13281 0.99609]\n",
      " [0.      0.36133 0.5     0.13281 0.99609]\n",
      " [0.      0.60352 0.5     0.12891 0.99609]\n",
      " [0.      0.45117 0.5     0.13281 0.99609]\n",
      " [0.      0.55469 0.5     0.13281 0.99609]\n",
      " [0.      0.71875 0.5     0.13281 0.99609]\n",
      " [0.      0.67188 0.5     0.12891 0.99609]\n",
      " [0.      0.44922 0.5     0.12891 0.99609]\n",
      " [0.      0.37109 0.5     0.12891 0.99609]\n",
      " [0.      0.70117 0.5     0.12891 0.99609]\n",
      " [0.      0.33984 0.5     0.12891 0.99609]\n",
      " [0.      0.36328 0.5     0.12891 0.99609]\n",
      " [0.      0.35742 0.5     0.13281 0.99609]\n",
      " [0.      0.53906 0.5     0.12891 0.99609]\n",
      " [0.      0.54492 0.5     0.12891 0.99609]\n",
      " [0.      0.42969 0.5     0.13281 0.99609]\n",
      " [0.      0.44141 0.5     0.13281 0.99609]\n",
      " [0.      0.45312 0.5     0.12891 0.99609]\n",
      " [0.      0.61523 0.5     0.13281 0.99609]\n",
      " [0.      0.33203 0.5     0.12891 0.99609]\n",
      " [0.      0.60547 0.5     0.12891 0.99609]\n",
      " [0.      0.65625 0.5     0.13281 0.99609]\n",
      " [0.      0.32031 0.5     0.12891 0.99609]\n",
      " [0.      0.28516 0.5     0.13281 0.99609]\n",
      " [0.      0.54492 0.5     0.12891 0.99609]\n",
      " [0.      0.73633 0.5     0.13281 0.99609]\n",
      " [0.      0.71289 0.5     0.13281 0.99609]\n",
      " [0.      0.69336 0.5     0.13281 0.99609]\n",
      " [0.      0.57031 0.5     0.13281 0.99609]\n",
      " [0.      0.625   0.5     0.13281 0.99609]\n",
      " [0.      0.44727 0.5     0.12891 0.99609]\n",
      " [0.      0.58203 0.5     0.13281 0.99609]\n",
      " [0.      0.48242 0.5     0.13281 0.99609]\n",
      " [0.      0.58594 0.5     0.12891 0.99609]\n",
      " [0.      0.64648 0.5     0.12891 0.99609]\n",
      " [0.      0.71289 0.5     0.13281 0.99609]\n",
      " [0.      0.36719 0.5     0.12891 0.99609]\n",
      " [0.      0.70312 0.5     0.13281 0.99609]\n",
      " [0.      0.70312 0.5     0.13281 0.99609]\n",
      " [0.      0.37109 0.5     0.13281 0.99609]\n",
      " [0.      0.57812 0.5     0.13281 0.99609]\n",
      " [0.      0.71094 0.5     0.12891 0.99609]\n",
      " [0.      0.51953 0.5     0.12891 0.99609]\n",
      " [0.      0.4707  0.5     0.13281 0.99609]\n",
      " [0.      0.30664 0.5     0.13281 0.99609]\n",
      " [0.      0.25977 0.5     0.13281 0.99609]\n",
      " [0.      0.51953 0.5     0.13281 0.99609]\n",
      " [0.      0.27148 0.5     0.12891 0.99609]\n",
      " [0.      0.45312 0.5     0.13281 0.99609]\n",
      " [0.      0.51562 0.5     0.13281 0.99609]\n",
      " [0.      0.64453 0.5     0.13281 0.99609]\n",
      " [0.      0.26758 0.5     0.13281 0.99609]\n",
      " [0.      0.38086 0.5     0.13281 0.99609]\n",
      " [0.      0.43359 0.5     0.13281 0.99609]\n",
      " [0.      0.75391 0.5     0.12891 0.99609]\n",
      " [0.      0.62109 0.5     0.13281 0.99609]\n",
      " [0.      0.49414 0.5     0.13281 0.99609]\n",
      " [0.      0.47266 0.5     0.13281 0.99609]\n",
      " [0.      0.30859 0.5     0.13281 0.99609]\n",
      " [0.      0.51758 0.5     0.13281 0.99609]\n",
      " [0.      0.29297 0.5     0.13281 0.99609]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.3315303e-05  4.9030885e-01  5.1843393e-01  1.3186795e-01\n",
      "   1.0663934e+00]\n",
      " [ 1.1448516e-05  4.7389084e-01  5.0392431e-01  1.3155796e-01\n",
      "   1.0112556e+00]\n",
      " [-3.7586200e-05  4.7454661e-01  4.9398410e-01  1.3136029e-01\n",
      "   9.7341895e-01]\n",
      " [-9.6763251e-06  4.1680637e-01  4.9938130e-01  1.3140228e-01\n",
      "   9.9416387e-01]\n",
      " [ 1.2390927e-04  4.8062688e-01  5.2661598e-01  1.3201672e-01\n",
      "   1.0975852e+00]\n",
      " [ 6.2833715e-05  4.7228980e-01  5.1427823e-01  1.3175875e-01\n",
      "   1.0506217e+00]\n",
      " [-5.9846789e-06  4.8243815e-01  5.0036675e-01  1.3149843e-01\n",
      "   9.9772727e-01]\n",
      " [ 8.7239547e-05  4.9170211e-01  5.1925820e-01  1.3188833e-01\n",
      "   1.0696275e+00]\n",
      " [ 9.6430944e-05  5.1238608e-01  5.2105331e-01  1.3195467e-01\n",
      "   1.0763146e+00]\n",
      " [ 2.3764034e-05  4.7409111e-01  5.0637662e-01  1.3160408e-01\n",
      "   1.0205917e+00]\n",
      " [ 1.0692747e-06  4.7678927e-01  5.0180078e-01  1.3151804e-01\n",
      "   1.0032160e+00]\n",
      " [ 5.4810836e-05  4.7375792e-01  5.1270366e-01  1.3173190e-01\n",
      "   1.0446509e+00]\n",
      " [-2.8651673e-05  4.4384813e-01  4.9582386e-01  1.3135403e-01\n",
      "   9.8044801e-01]\n",
      " [ 4.2863830e-05  5.0650603e-01  5.1024234e-01  1.3173130e-01\n",
      "   1.0351841e+00]\n",
      " [-8.0832979e-06  4.3545556e-01  4.9993014e-01  1.3142242e-01\n",
      "   9.9614382e-01]\n",
      " [ 2.2744061e-06  4.6509576e-01  5.0203001e-01  1.3150577e-01\n",
      "   1.0039970e+00]\n",
      " [ 1.2256566e-04  6.2413192e-01  5.2652073e-01  1.3224180e-01\n",
      "   1.0968561e+00]\n",
      " [ 7.7586737e-05  5.3867054e-01  5.1734197e-01  1.3192821e-01\n",
      "   1.0621967e+00]\n",
      " [ 3.6769314e-05  4.6443865e-01  5.0900930e-01  1.3164282e-01\n",
      "   1.0306036e+00]\n",
      " [ 2.3749948e-05  5.4098833e-01  5.0643921e-01  1.3171595e-01\n",
      "   1.0204786e+00]\n",
      " [ 2.3305067e-05  4.6104273e-01  5.0629544e-01  1.3158584e-01\n",
      "   1.0202601e+00]\n",
      " [ 1.1658395e-04  5.2215827e-01  5.2513832e-01  1.3205190e-01\n",
      "   1.0918014e+00]\n",
      " [ 1.4273869e-04  5.3997236e-01  5.3041863e-01  1.3218187e-01\n",
      "   1.1118199e+00]\n",
      " [ 9.6567092e-05  5.1185691e-01  5.2108341e-01  1.3195494e-01\n",
      "   1.0763803e+00]\n",
      " [ 8.7196589e-05  4.8211855e-01  5.1924342e-01  1.3187511e-01\n",
      "   1.0694098e+00]\n",
      " [-3.8557919e-05  4.6751940e-01  4.9378163e-01  1.3134547e-01\n",
      "   9.7268176e-01]\n",
      " [ 3.5817502e-05  4.9173504e-01  5.0880235e-01  1.3167994e-01\n",
      "   1.0297409e+00]\n",
      " [ 5.2630203e-05  4.6364167e-01  5.1222014e-01  1.3170570e-01\n",
      "   1.0428910e+00]\n",
      " [ 4.6856469e-05  4.8959106e-01  5.1105380e-01  1.3172258e-01\n",
      "   1.0382591e+00]\n",
      " [-5.3514377e-05  4.7428033e-01  4.9076617e-01  1.3129695e-01\n",
      "   9.6115518e-01]\n",
      " [ 2.2972468e-05  4.8565871e-01  5.0625855e-01  1.3162170e-01\n",
      "   1.0201577e+00]\n",
      " [ 5.0436647e-05  5.1245224e-01  5.1183850e-01  1.3177696e-01\n",
      "   1.0411618e+00]\n",
      " [ 4.7148613e-05  4.4825888e-01  5.1110590e-01  1.3166346e-01\n",
      "   1.0386343e+00]\n",
      " [ 1.1127611e-04  5.1526022e-01  5.2409667e-01  1.3201945e-01\n",
      "   1.0879076e+00]\n",
      " [ 7.5357792e-05  4.8287976e-01  5.1681274e-01  1.3182473e-01\n",
      "   1.0602818e+00]\n",
      " [ 9.6160802e-05  5.7505828e-01  5.2112025e-01  1.3205570e-01\n",
      "   1.0763689e+00]\n",
      " [ 1.7037790e-05  4.6711177e-01  5.0502717e-01  1.3156757e-01\n",
      "   1.0154668e+00]\n",
      " [ 3.6121812e-05  4.6717188e-01  5.0893140e-01  1.3164879e-01\n",
      "   1.0303729e+00]\n",
      " [ 1.0871509e-04  5.1949179e-01  5.2352786e-01  1.3201521e-01\n",
      "   1.0856737e+00]\n",
      " [-2.0635605e-05  4.2503786e-01  4.9730957e-01  1.3136132e-01\n",
      "   9.8617911e-01]\n",
      " [ 5.9452199e-05  4.9468803e-01  5.1362526e-01  1.3178083e-01\n",
      "   1.0481161e+00]\n",
      " [ 3.3105141e-05  5.1626962e-01  5.0834560e-01  1.3171682e-01\n",
      "   1.0279094e+00]\n",
      " [-2.6747177e-05  4.1707450e-01  4.9597758e-01  1.3133188e-01\n",
      "   9.8118699e-01]\n",
      " [ 7.9808175e-05  5.1939940e-01  5.1770568e-01  1.3189849e-01\n",
      "   1.0634655e+00]\n",
      " [ 6.1357860e-06  5.1681840e-01  5.0287318e-01  1.3160603e-01\n",
      "   1.0070711e+00]\n",
      " [ 5.5613753e-05  5.1025653e-01  5.1282465e-01  1.3178784e-01\n",
      "   1.0450803e+00]\n",
      " [ 4.4743589e-05  4.4408685e-01  5.1058763e-01  1.3164897e-01\n",
      "   1.0366982e+00]\n",
      " [-4.2992062e-05  3.9340255e-01  4.9227616e-01  1.3125494e-01\n",
      "   9.6713293e-01]\n",
      " [ 9.3197101e-05  5.2196991e-01  5.2040732e-01  1.3195905e-01\n",
      "   1.0736501e+00]\n",
      " [ 4.6211295e-05  4.5371014e-01  5.1094508e-01  1.3166866e-01\n",
      "   1.0379874e+00]\n",
      " [ 5.7081925e-06  4.4045097e-01  5.0278091e-01  1.3148379e-01\n",
      "   1.0069333e+00]\n",
      " [-3.5442121e-05  4.3305159e-01  4.9443367e-01  1.3131087e-01\n",
      "   9.7517097e-01]\n",
      " [-4.0604966e-05  4.6066833e-01  4.9343023e-01  1.3133271e-01\n",
      "   9.7135699e-01]\n",
      " [ 5.4523000e-05  4.9673051e-01  5.1261395e-01  1.3176528e-01\n",
      "   1.0441312e+00]\n",
      " [ 1.7322192e-05  4.4533300e-01  5.0510019e-01  1.3153657e-01\n",
      "   1.0158198e+00]\n",
      " [ 4.2213302e-05  4.7263062e-01  5.1011229e-01  1.3167624e-01\n",
      "   1.0348510e+00]\n",
      " [-1.0701828e-05  4.2252326e-01  4.9926257e-01  1.3140398e-01\n",
      "   9.9360025e-01]\n",
      " [ 3.2108510e-05  5.3481400e-01  5.0814110e-01  1.3173740e-01\n",
      "   1.0271651e+00]\n",
      " [-4.3403881e-05  4.2205781e-01  4.9274796e-01  1.3126494e-01\n",
      "   9.6880281e-01]\n",
      " [ 1.2287131e-04  5.0626588e-01  5.2641672e-01  1.3204978e-01\n",
      "   1.0968372e+00]\n",
      " [ 1.1834764e-04  5.1391327e-01  5.2548462e-01  1.3204454e-01\n",
      "   1.0931300e+00]\n",
      " [ 7.4714713e-05  5.1852536e-01  5.1669681e-01  1.3187855e-01\n",
      "   1.0597090e+00]\n",
      " [ 4.8175338e-05  4.4206762e-01  5.1123476e-01  1.3166460e-01\n",
      "   1.0390829e+00]\n",
      " [ 6.2359672e-05  5.0534415e-01  5.1419657e-01  1.3180859e-01\n",
      "   1.0501765e+00]\n",
      " [ 1.3253815e-04  5.1677215e-01  5.2842927e-01  1.3211064e-01\n",
      "   1.1042949e+00]\n",
      " [ 3.4721917e-05  4.7027889e-01  5.0863886e-01  1.3164631e-01\n",
      "   1.0292369e+00]\n",
      " [ 5.9922051e-05  5.1768190e-01  5.1373583e-01  1.3182214e-01\n",
      "   1.0483845e+00]\n",
      " [ 9.4069110e-05  5.0012428e-01  5.2059764e-01  1.3192584e-01\n",
      "   1.0746903e+00]\n",
      " [ 8.1676058e-05  5.1696944e-01  5.1808715e-01  1.3190287e-01\n",
      "   1.0649686e+00]\n",
      " [-3.8730795e-06  4.7875619e-01  5.0078154e-01  1.3150185e-01\n",
      "   9.9924052e-01]\n",
      " [ 3.6933983e-05  4.9339461e-01  5.0906289e-01  1.3168834e-01\n",
      "   1.0307298e+00]\n",
      " [ 2.5035406e-05  4.7940868e-01  5.0663763e-01  1.3161799e-01\n",
      "   1.0215031e+00]\n",
      " [-3.9324514e-06  4.7894871e-01  5.0080287e-01  1.3150162e-01\n",
      "   9.9927020e-01]\n",
      " [-1.2131932e-05  4.4779983e-01  4.9913329e-01  1.3142136e-01\n",
      "   9.9301517e-01]\n",
      " [ 4.2750442e-05  4.9747881e-01  5.1022041e-01  1.3171963e-01\n",
      "   1.0349367e+00]\n",
      " [-1.3790850e-05  4.4392607e-01  4.9882692e-01  1.3141356e-01\n",
      "   9.9185228e-01]\n",
      " [ 4.1614810e-05  4.8512548e-01  5.0998139e-01  1.3169304e-01\n",
      "   1.0342542e+00]\n",
      " [ 5.5585464e-05  5.3991830e-01  5.1290309e-01  1.3184266e-01\n",
      "   1.0452844e+00]\n",
      " [ 4.0318700e-06  4.6749210e-01  5.0240135e-01  1.3151588e-01\n",
      "   1.0054473e+00]\n",
      " [ 8.9195324e-05  5.2479696e-01  5.1958990e-01  1.3194396e-01\n",
      "   1.0707421e+00]\n",
      " [ 6.9662579e-05  5.0817180e-01  5.1567924e-01  1.3184230e-01\n",
      "   1.0558105e+00]\n",
      " [ 1.8269464e-05  4.7902733e-01  5.0532734e-01  1.3159858e-01\n",
      "   1.0165001e+00]\n",
      " [ 1.4079444e-05  4.3601435e-01  5.0436807e-01  1.3151534e-01\n",
      "   1.0130420e+00]\n",
      " [-8.7424414e-06  4.0317005e-01  4.9923414e-01  1.3140386e-01\n",
      "   9.9362373e-01]\n",
      " [-4.8926915e-05  4.6890295e-01  4.9168420e-01  1.3130611e-01\n",
      "   9.6468675e-01]\n",
      " [-2.0951149e-05  4.2648798e-01  4.9729407e-01  1.3136125e-01\n",
      "   9.8611736e-01]\n",
      " [ 8.0732629e-05  4.7274172e-01  5.1790583e-01  1.3183141e-01\n",
      "   1.0644916e+00]\n",
      " [-5.7938392e-05  4.0500462e-01  4.8961687e-01  1.3119107e-01\n",
      "   9.5702696e-01]\n",
      " [ 6.1136903e-05  5.0153625e-01  5.1390862e-01  1.3179645e-01\n",
      "   1.0491408e+00]\n",
      " [ 3.8372236e-05  5.0474501e-01  5.0932711e-01  1.3171098e-01\n",
      "   1.0316715e+00]\n",
      " [-5.1031122e-05  4.2855546e-01  4.9131006e-01  1.3124019e-01\n",
      "   9.6321404e-01]\n",
      " [ 4.6605710e-05  4.6627527e-01  5.1102877e-01  1.3168545e-01\n",
      "   1.0382478e+00]\n",
      " [-3.7422520e-05  4.4059789e-01  4.9404147e-01  1.3131239e-01\n",
      "   9.7369266e-01]\n",
      " [ 2.9515533e-05  5.6830728e-01  5.0763249e-01  1.3178253e-01\n",
      "   1.0250424e+00]\n",
      " [ 2.6221445e-05  5.6356931e-01  5.0695872e-01  1.3176146e-01\n",
      "   1.0226005e+00]\n",
      " [ 3.9891747e-05  4.9189466e-01  5.0964439e-01  1.3169821e-01\n",
      "   1.0328776e+00]\n",
      " [ 6.7415240e-05  4.5668206e-01  5.1524091e-01  1.3175391e-01\n",
      "   1.0543764e+00]\n",
      " [ 6.8311929e-06  4.4765040e-01  5.0293976e-01  1.3149811e-01\n",
      "   1.0075151e+00]\n",
      " [ 5.1760871e-05  4.8051858e-01  5.1207608e-01  1.3173133e-01\n",
      "   1.0421879e+00]\n",
      " [-7.2884490e-05  4.1940740e-01  4.8684889e-01  1.3113900e-01\n",
      "   9.4637787e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
